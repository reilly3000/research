<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;50 of 56,162 results for all: <span class="mathjax">agents</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="agents">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option selected value="all">All fields</option><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=agents&amp;terms-0-field=all&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option selected value="all">All fields</option><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="agents">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
                                     
          
          <li>
            <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=50"
              class="pagination-link "
              aria-label="Page 2"
              aria-current="page">2
            </a>
          </li>
          
          <li>
            <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=100"
              class="pagination-link "
              aria-label="Page 3"
              aria-current="page">3
            </a>
          </li>
          
          <li>
            <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=150"
              class="pagination-link "
              aria-label="Page 4"
              aria-current="page">4
            </a>
          </li>
          
          <li>
            <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=200"
              class="pagination-link "
              aria-label="Page 5"
              aria-current="page">5
            </a>
          </li>
          
          <li><span class="pagination-ellipsis">&hellip;</span></li>
        
      
    </ul>
  </nav>
  



<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13671">arXiv:2512.13671</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13671">pdf</a>, <a href="https://arxiv.org/ps/2512.13671">ps</a>, <a href="https://arxiv.org/format/2512.13671">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AgentIAD: Tool-Augmented Single-<span class="search-hit mathjax">Agent</span> for Industrial Anomaly Detection
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Miao%2C+J">Junwen Miao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+P">Penghui Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yi Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yu Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yan Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13671v1-abstract-short" style="display: inline;">
        &hellip;vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We propose AgentIAD, a tool-driven <span class="search-hit mathjax">agentic</span> framework that enables multi-stage visual inspection. The <span class="search-hit mathjax">agent</span> is equipped with a Perceptive Zoomer (PZ) for localized fine-grained anal&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13671v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13671v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13671v1-abstract-full" style="display: none;">
        Industrial anomaly detection (IAD) is difficult due to the scarcity of normal reference samples and the subtle, localized nature of many defects. Single-pass vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We propose AgentIAD, a tool-driven <span class="search-hit mathjax">agentic</span> framework that enables multi-stage visual inspection. The <span class="search-hit mathjax">agent</span> is equipped with a Perceptive Zoomer (PZ) for localized fine-grained analysis and a Comparative Retriever (CR) for querying normal exemplars when evidence is ambiguous. To teach these inspection behaviors, we construct structured perceptive and comparative trajectories from the MMAD dataset and train the model in two stages: supervised fine-tuning followed by reinforcement learning. A two-part reward design drives this process: a perception reward that supervises classification accuracy, spatial alignment, and type correctness, and a behavior reward that encourages efficient tool use. Together, these components enable the model to refine its judgment through step-wise observation, zooming, and verification. AgentIAD achieves a new state-of-the-art 97.62% classification accuracy on MMAD, surpassing prior MLLM-based approaches while producing transparent and interpretable inspection traces.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13671v1-abstract-full').style.display = 'none'; document.getElementById('2512.13671v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13627">arXiv:2512.13627</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13627">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="General Economics">econ.GN</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Job insecurity, equilibrium determinacy and E-stability in a New Keynesian model with asymmetric information. Theory and simulation analysis
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vota%2C+L">Luca Vota</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Errichiello%2C+L">Luisa Errichiello</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13627v1-abstract-short" style="display: inline;">
        &hellip;formed by the dynamic IS curve, New Keynesian Phillips curve, and Taylor rule equations is augmented with labor market frictions. The model features partially informed private <span class="search-hit mathjax">agents</span> who receive a noisy signal about economic fundamentals from a fully informed public sector. When monetary policy satisfies the Taylor principle, the equilibrium is unique and de&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13627v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13627v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13627v1-abstract-full" style="display: none;">
        Departing from the dominant approach focused on individual and meso-level determinants, this manuscript develops a macroeconomic formalization of job insecurity within a New Keynesian framework in which the block formed by the dynamic IS curve, New Keynesian Phillips curve, and Taylor rule equations is augmented with labor market frictions. The model features partially informed private <span class="search-hit mathjax">agents</span> who receive a noisy signal about economic fundamentals from a fully informed public sector. When monetary policy satisfies the Taylor principle, the equilibrium is unique and determinate. However, the release of news about current or future fundamentals can still generate a form of &#34;Paradox of Transparency&#34; through general equilibrium interactions between aggregate demand and monetary policy. When the Taylor principle is violated, belief-driven equilibria may emerge. Validation exercises based on the Simulated Method of Moments confirm the empirical plausibility of the model&#39;s key implications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13627v1-abstract-full').style.display = 'none'; document.getElementById('2512.13627v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13564">arXiv:2512.13564</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13564">pdf</a>, <a href="https://arxiv.org/ps/2512.13564">ps</a>, <a href="https://arxiv.org/format/2512.13564">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Memory in the Age of AI <span class="search-hit mathjax">Agents</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+Y">Yuyang Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+S">Shichun Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yue%2C+Y">Yanwei Yue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+G">Guibin Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+B">Boyang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+F">Fangyi Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+J">Jiahang Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+H">Honglin Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dou%2C+S">Shihan Dou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xi%2C+Z">Zhiheng Xi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jin%2C+S">Senjie Jin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tan%2C+J">Jiejun Tan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+Y">Yanbin Yin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+J">Jiongnan Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Z">Zeyu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+Z">Zhongxiang Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Y">Yutao Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+H">Hao Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+B">Boci Peng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+Z">Zhenrong Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+X">Xuanbo Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+J">Jiaxin Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+X">Xinlei Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+Z">Zhenhong Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+Z">Zewen Hu</a>
      , et al. (22 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13564v1-abstract-short" style="display: inline;">
        Memory has emerged, and will continue to remain, a core capability of foundation model-based <span class="search-hit mathjax">agents</span>. As research on&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13564v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13564v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13564v1-abstract-full" style="display: none;">
        Memory has emerged, and will continue to remain, a core capability of foundation model-based <span class="search-hit mathjax">agents</span>. As research on <span class="search-hit mathjax">agent</span> memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of <span class="search-hit mathjax">agent</span> memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporary <span class="search-hit mathjax">agent</span> memory systems. This work aims to provide an up-to-date landscape of current <span class="search-hit mathjax">agent</span> memory research. We begin by clearly delineating the scope of <span class="search-hit mathjax">agent</span> memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine <span class="search-hit mathjax">agent</span> memory through the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations of <span class="search-hit mathjax">agent</span> memory, namely token-level, parametric, and latent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary of memory benchmarks and open-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including memory automation, reinforcement learning integration, multimodal memory, multi-<span class="search-hit mathjax">agent</span> memory, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future <span class="search-hit mathjax">agentic</span> intelligence.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13564v1-abstract-full').style.display = 'none'; document.getElementById('2512.13564v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13526">arXiv:2512.13526</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13526">pdf</a>, <a href="https://arxiv.org/ps/2512.13526">ps</a>, <a href="https://arxiv.org/format/2512.13526">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Async Control: Stress-testing Asynchronous Control Measures for LLM <span class="search-hit mathjax">Agents</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Stickland%2C+A+C">Asa Cooper Stickland</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Michelfeit%2C+J">Jan Michelfeit</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mani%2C+A">Arathi Mani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Griffin%2C+C">Charlie Griffin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Matthews%2C+O">Ollie Matthews</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Korbak%2C+T">Tomek Korbak</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Inglis%2C+R">Rogan Inglis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Makins%2C+O">Oliver Makins</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cooney%2C+A">Alan Cooney</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13526v1-abstract-short" style="display: inline;">
        LLM-based software engineering <span class="search-hit mathjax">agents</span> are increasingly used in real-world development tasks, often with access to sensitive data or security-critical codebases. Such&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13526v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13526v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13526v1-abstract-full" style="display: none;">
        LLM-based software engineering <span class="search-hit mathjax">agents</span> are increasingly used in real-world development tasks, often with access to sensitive data or security-critical codebases. Such <span class="search-hit mathjax">agents</span> could intentionally sabotage these codebases if they were misaligned. We investigate asynchronous monitoring, in which a monitoring system reviews <span class="search-hit mathjax">agent</span> actions after the fact. Unlike synchronous monitoring, this approach does not impose runtime latency, while still attempting to disrupt attacks before irreversible harm occurs. We treat monitor development as an adversarial game between a blue team (who design monitors) and a red team (who create sabotaging <span class="search-hit mathjax">agents</span>). We attempt to set the game rules such that they upper bound the sabotage potential of an <span class="search-hit mathjax">agent</span> based on Claude 4.1 Opus. To ground this game in a realistic, high-stakes deployment scenario, we develop a suite of 5 diverse software engineering environments that simulate tasks that an <span class="search-hit mathjax">agent</span> might perform within an AI developer&#39;s internal infrastructure. Over the course of the game, we develop an ensemble monitor that achieves a 6% false negative rate at 1% false positive rate on a held out test environment. Then, we estimate risk of sabotage at deployment time by extrapolating from our monitor&#39;s false negative rate. We describe one simple model for this extrapolation, present a sensitivity analysis, and describe situations in which the model would be invalid. Code is available at: https://github.com/UKGovernmentBEIS/async-control.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13526v1-abstract-full').style.display = 'none'; document.getElementById('2512.13526v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13522">arXiv:2512.13522</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13522">pdf</a>, <a href="https://arxiv.org/ps/2512.13522">ps</a>, <a href="https://arxiv.org/format/2512.13522">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Collective Annealing by Switching Temperatures: a Boltzmann-type description
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Blondeel%2C+F">Frédéric Blondeel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pareschi%2C+L">Lorenzo Pareschi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Samaey%2C+G">Giovanni Samaey</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13522v1-abstract-short" style="display: inline;">
        &hellip;to ensure convergence to global minima. In this work, we propose Collective Annealing by Switching Temperatures (CAST), a novel collective simulated annealing dynamic in which <span class="search-hit mathjax">agents</span> interact to learn an adaptive cooling schedule. Inspired by the particle-swapping mechanism of parallel tempering, we introduce a Boltzmann-type framework in which particles exc&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13522v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13522v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13522v1-abstract-full" style="display: none;">
        The design of effective cooling strategies is a crucial component in simulated annealing algorithms based on the Metropolis method. Traditionally, this is achieved through inverse logarithmic decays of the temperature to ensure convergence to global minima. In this work, we propose Collective Annealing by Switching Temperatures (CAST), a novel collective simulated annealing dynamic in which <span class="search-hit mathjax">agents</span> interact to learn an adaptive cooling schedule. Inspired by the particle-swapping mechanism of parallel tempering, we introduce a Boltzmann-type framework in which particles exchange temperatures through stochastic binary interactions. This process leads to a gradual decrease of the average temperature in the system. Numerical results demonstrate that the proposed approach consistently outperforms classical simulated annealing with both logarithmic and geometric cooling schedules, particularly in terms of convergence speed.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13522v1-abstract-full').style.display = 'none'; document.getElementById('2512.13522v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13517">arXiv:2512.13517</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13517">pdf</a>, <a href="https://arxiv.org/ps/2512.13517">ps</a>, <a href="https://arxiv.org/format/2512.13517">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neurons and Cognition">q-bio.NC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Deep Learning Model of Mental Rotation Informed by Interactive VR Experiments
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Khazoum%2C+R">Raymond Khazoum</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fernandes%2C+D">Daniela Fernandes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Krylov%2C+A">Aleksandr Krylov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Q">Qin Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deny%2C+S">Stephane Deny</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13517v1-abstract-short" style="display: inline;">
        &hellip;spatial representations of objects, (2) a neuro-symbolic object encoder, deriving symbolic descriptions of objects from these spatial representations, and (3) a neural decision <span class="search-hit mathjax">agent</span>, comparing these symbolic descriptions to prescribe rotation simulations in 3D latent space via a recurrent pathway. Our model design is guided by the abundant experimental lite&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13517v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13517v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13517v1-abstract-full" style="display: none;">
        Mental rotation -- the ability to compare objects seen from different viewpoints -- is a fundamental example of mental simulation and spatial world modelling in humans. Here we propose a mechanistic model of human mental rotation, leveraging advances in deep, equivariant, and neuro-symbolic learning. Our model consists of three stacked components: (1) an equivariant neural encoder, taking images as input and producing 3D spatial representations of objects, (2) a neuro-symbolic object encoder, deriving symbolic descriptions of objects from these spatial representations, and (3) a neural decision <span class="search-hit mathjax">agent</span>, comparing these symbolic descriptions to prescribe rotation simulations in 3D latent space via a recurrent pathway. Our model design is guided by the abundant experimental literature on mental rotation, which we complemented with experiments in VR where participants could at times manipulate the objects to compare, providing us with additional insights into the cognitive process of mental rotation. Our model captures well the performance, response times and behavior of participants in our and others&#39; experiments. The necessity of each model component is shown through systematic ablations. Our work adds to a recent collection of deep neural models of human spatial reasoning, further demonstrating the potency of integrating deep, equivariant, and symbolic representations to model the human mind.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13517v1-abstract-full').style.display = 'none'; document.getElementById('2512.13517v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13481">arXiv:2512.13481</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13481">pdf</a>, <a href="https://arxiv.org/ps/2512.13481">ps</a>, <a href="https://arxiv.org/format/2512.13481">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-<span class="search-hit mathjax">Agent</span> Settings
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pungalia%2C+O">Ojas Pungalia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Upadhyay%2C+R">Rashi Upadhyay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mishra%2C+A">Abhishek Mishra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=H%2C+A">Abhiram H</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alladi%2C+T">Tejasvi Alladi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yenuganti%2C+S">Sujan Yenuganti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+D">Dhruv Kumar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13481v1-abstract-short" style="display: inline;">
        &hellip;instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-<span class="search-hit mathjax">agent</span> systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13481v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13481v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13481v1-abstract-full" style="display: none;">
        Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-<span class="search-hit mathjax">agent</span> systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13481v1-abstract-full').style.display = 'none'; document.getElementById('2512.13481v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Under Review</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13438">arXiv:2512.13438</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13438">pdf</a>, <a href="https://arxiv.org/ps/2512.13438">ps</a>, <a href="https://arxiv.org/format/2512.13438">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        From User Interface to <span class="search-hit mathjax">Agent</span> Interface: Efficiency Optimization of UI Representations for LLM <span class="search-hit mathjax">Agents</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ran%2C+D">Dezhi Ran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gong%2C+Z">Zhi Gong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+Y">Yuzhe Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+M">Mengzhou Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+Y">Yuan Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+H">Haochuan Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Hengyu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zeng%2C+X">Xia Zeng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+G">Gang Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yao%2C+L">Liangchao Yao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deng%2C+Y">Yuetang Deng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+W">Wei Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+T">Tao Xie</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13438v1-abstract-short" style="display: inline;">
        While Large Language Model (LLM) <span class="search-hit mathjax">agents</span> show great potential for automated UI navigation such as automated UI testing and AI assistants, their efficiency has been largely overlooked. Our motivating study reveals that inefficient UI representation creates a critical performance bottleneck. However, UI representation optimization, formulated as the task of aut&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13438v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13438v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13438v1-abstract-full" style="display: none;">
        While Large Language Model (LLM) <span class="search-hit mathjax">agents</span> show great potential for automated UI navigation such as automated UI testing and AI assistants, their efficiency has been largely overlooked. Our motivating study reveals that inefficient UI representation creates a critical performance bottleneck. However, UI representation optimization, formulated as the task of automatically generating programs that transform UI representations, faces two unique challenges. First, the lack of Boolean oracles, which traditional program synthesis uses to decisively validate semantic correctness, poses a fundamental challenge to co-optimization of token efficiency and completeness. Second, the need to process large, complex UI trees as input while generating long, compositional transformation programs, making the search space vast and error-prone. Toward addressing the preceding limitations, we present UIFormer, the first automated optimization framework that synthesizes UI transformation programs by conducting constraint-based optimization with structured decomposition of the complex synthesis task. First, UIFormer restricts the program space using a domain-specific language (DSL) that captures UI-specific operations. Second, UIFormer conducts LLM-based iterative refinement with correctness and efficiency rewards, providing guidance for achieving the efficiency-completeness co-optimization. UIFormer operates as a lightweight plugin that applies transformation programs for seamless integration with existing LLM <span class="search-hit mathjax">agents</span>, requiring minimal modifications to their core logic. Evaluations across three UI navigation benchmarks spanning Android and Web platforms with five LLMs demonstrate that UIFormer achieves 48.7% to 55.8% token reduction with minimal runtime overhead while maintaining or improving <span class="search-hit mathjax">agent</span> performance. Real-world industry deployment at WeChat further validates the practical impact of UIFormer.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13438v1-abstract-full').style.display = 'none'; document.getElementById('2512.13438v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13399">arXiv:2512.13399</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13399">pdf</a>, <a href="https://arxiv.org/ps/2512.13399">ps</a>, <a href="https://arxiv.org/format/2512.13399">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Differentiable Evolutionary Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+S">Sitao Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+T">Tianle Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+X">Xuhan Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+X">Xunjian Yin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zou%2C+D">Difan Zou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13399v1-abstract-short" style="display: inline;">
        The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous <span class="search-hit mathjax">agents</span> for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13399v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13399v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13399v1-abstract-full" style="display: none;">
        The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous <span class="search-hit mathjax">agents</span> for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box, failing to capture the causal relationship between reward structure and task performance. To bridge this gap, we propose Differentiable Evolutionary Reinforcement Learning (DERL), a bilevel framework that enables the autonomous discovery of optimal reward signals. In DERL, a Meta-Optimizer evolves a reward function (i.e., Meta-Reward) by composing structured atomic primitives, guiding the training of an inner-loop policy. Crucially, unlike previous evolution, DERL is differentiable in its metaoptimization: it treats the inner-loop validation performance as a signal to update the Meta-Optimizer via reinforcement learning. This allows DERL to approximate the &#34;meta-gradient&#34; of task success, progressively learning to generate denser and more actionable feedback. We validate DERL across three distinct domains: robotic <span class="search-hit mathjax">agent</span> (ALFWorld), scientific simulation (ScienceWorld), and mathematical reasoning (GSM8k, MATH). Experimental results show that DERL achieves state-of-the-art performance on ALFWorld and ScienceWorld, significantly outperforming methods relying on heuristic rewards, especially in out-of-distribution scenarios. Analysis of the evolutionary trajectory demonstrates that DERL successfully captures the intrinsic structure of tasks, enabling selfimproving <span class="search-hit mathjax">agent</span> alignment without human intervention.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13399v1-abstract-full').style.display = 'none'; document.getElementById('2512.13399v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Work in Progress. We release our code and model at https://github.com/sitaocheng/DERL</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13385">arXiv:2512.13385</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13385">pdf</a>, <a href="https://arxiv.org/ps/2512.13385">ps</a>, <a href="https://arxiv.org/format/2512.13385">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Theoretical Economics">econ.TH</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Historical claims problems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gon%C3%A7alves-Dosantos%2C+J+C">Juan C. Gonçalves-Dosantos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mart%C3%ADnez%2C+R">Ricardo Martínez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moreno-Ternero%2C+J+D">Juan D. Moreno-Ternero</a>, 
      
      <a href="/search/?searchtype=author&amp;query=S%C3%A1nchez-Soriano%2C+J">Joaquín Sánchez-Soriano</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13385v1-abstract-short" style="display: inline;">
        We explore the resolution of claims problems with history. At a given period of time, a group of <span class="search-hit mathjax">agents</span> holds claims over an insufficient endowment, as they did in previous periods. The solution to the present-period problem might be influenced by the solutions at previous-periods problems (history). We introduce a natural historical operator, which extends&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13385v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13385v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13385v1-abstract-full" style="display: none;">
        We explore the resolution of claims problems with history. At a given period of time, a group of <span class="search-hit mathjax">agents</span> holds claims over an insufficient endowment, as they did in previous periods. The solution to the present-period problem might be influenced by the solutions at previous-periods problems (history). We introduce a natural historical operator, which extends standard rules (solving one-shot claims problems) to construct rules that solve claims problems with history. We study the preservation of properties by this operator and also obtain a characterization result for it.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13385v1-abstract-full').style.display = 'none'; document.getElementById('2512.13385v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13356">arXiv:2512.13356</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13356">pdf</a>, <a href="https://arxiv.org/ps/2512.13356">ps</a>, <a href="https://arxiv.org/format/2512.13356">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/ICSTCC62912.2024.10744717">10.1109/ICSTCC62912.2024.10744717 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gamal%2C+Z">Zeyad Gamal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mahran%2C+Y">Youssef Mahran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=El-Badawy%2C+A">Ayman El-Badawy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13356v1-abstract-short" style="display: inline;">
        &hellip;due to their potential applications in the control of multirotors. The Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm was used in this paper to train the RL <span class="search-hit mathjax">agent</span>. This algorithm is used for environments with continuous state and action spaces, similar to the TRAS, as it does not require a model of the system. The simulation results illustra&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13356v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13356v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13356v1-abstract-full" style="display: none;">
        This paper proposes a reinforcement learning (RL) framework for controlling and stabilizing the Twin Rotor Aerodynamic System (TRAS) at specific pitch and azimuth angles and tracking a given trajectory. The complex dynamics and non-linear characteristics of the TRAS make it challenging to control using traditional control algorithms. However, recent developments in RL have attracted interest due to their potential applications in the control of multirotors. The Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm was used in this paper to train the RL <span class="search-hit mathjax">agent</span>. This algorithm is used for environments with continuous state and action spaces, similar to the TRAS, as it does not require a model of the system. The simulation results illustrated the effectiveness of the RL control method. Next, external disturbances in the form of wind disturbances were used to test the controller&#39;s effectiveness compared to conventional PID controllers. Lastly, experiments on a laboratory setup were carried out to confirm the controller&#39;s effectiveness in real-world applications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13356v1-abstract-full').style.display = 'none'; document.getElementById('2512.13356v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This is the Author Accepted Manuscript version of a paper accepted for publication. The final published version is available via IEEE Xplore</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2024 28th IEEE International Conference on System Theory, Control and Computing (ICSTCC)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13323">arXiv:2512.13323</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13323">pdf</a>, <a href="https://arxiv.org/ps/2512.13323">ps</a>, <a href="https://arxiv.org/format/2512.13323">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Error-Driven Prompt Optimization for Arithmetic Reasoning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=P%C3%A1ndy%2C+%C3%81">Árpád Pándy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lakatos%2C+R">Róbert Lakatos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hajdu%2C+A">András Hajdu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13323v1-abstract-short" style="display: inline;">
        Recent advancements in artificial intelligence have sparked interest in industrial <span class="search-hit mathjax">agents</span> capable of supporting analysts in regulated sectors, such as finance and healthcare, within tabular data workflows. A key capability for such systems is performing accurate arithmetic operations on structured data while ensuring sensitive information never leaves secure&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13323v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13323v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13323v1-abstract-full" style="display: none;">
        Recent advancements in artificial intelligence have sparked interest in industrial <span class="search-hit mathjax">agents</span> capable of supporting analysts in regulated sectors, such as finance and healthcare, within tabular data workflows. A key capability for such systems is performing accurate arithmetic operations on structured data while ensuring sensitive information never leaves secure, on-premises environments. Here, we introduce an error-driven optimization framework for arithmetic reasoning that enhances a Code Generation <span class="search-hit mathjax">Agent</span> (CGA), specifically applied to on-premises small language models (SLMs). Through a systematic evaluation of a leading SLM (Qwen3 4B), we find that while the base model exhibits fundamental limitations in arithmetic tasks, our proposed error-driven method, which clusters erroneous predictions to refine prompt-rules iteratively, dramatically improves performance, elevating the model&#39;s accuracy to 70.8\%. Our results suggest that developing reliable, interpretable, and industrially deployable AI assistants can be achieved not only through costly fine-tuning but also via systematic, error-driven prompt optimization, enabling small models to surpass larger language models (GPT-3.5 Turbo) in a privacy-compliant manner.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13323v1-abstract-full').style.display = 'none'; document.getElementById('2512.13323v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13297">arXiv:2512.13297</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13297">pdf</a>, <a href="https://arxiv.org/ps/2512.13297">ps</a>, <a href="https://arxiv.org/format/2512.13297">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        MedInsightBench: Evaluating Medical Analytics <span class="search-hit mathjax">Agents</span> Through Multi-Step Insight Discovery in Multimodal Medical Data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Z">Zhenghao Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+C">Chuxue Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+S">Sirui Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+Y">Yuanfeng Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+X">Xing Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+C+C">Caleb Chen Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+Y">Yike Guo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13297v1-abstract-short" style="display: inline;">
        &hellip;benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and <span class="search-hit mathjax">agent</span> frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13297v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13297v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13297v1-abstract-full" style="display: none;">
        In medical data analysis, extracting deep insights from complex, multi-modal datasets is essential for improving patient care, increasing diagnostic accuracy, and optimizing healthcare operations. However, there is currently a lack of high-quality datasets specifically designed to evaluate the ability of large multi-modal models (LMMs) to discover medical insights. In this paper, we introduce MedInsightBench, the first benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and <span class="search-hit mathjax">agent</span> frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendations. Our analysis indicates that existing LMMs exhibit limited performance on MedInsightBench, which is primarily attributed to their challenges in extracting multi-step, deep insights and the absence of medical expertise. Therefore, we propose MedInsightAgent, an automated <span class="search-hit mathjax">agent</span> framework for medical data analysis, composed of three modules: Visual Root Finder, Analytical Insight <span class="search-hit mathjax">Agent</span>, and Follow-up Question Composer. Experiments on MedInsightBench highlight pervasive challenges and demonstrate that MedInsightAgent can improve the performance of general LMMs in medical data insight discovery.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13297v1-abstract-full').style.display = 'none'; document.getElementById('2512.13297v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13278">arXiv:2512.13278</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13278">pdf</a>, <a href="https://arxiv.org/ps/2512.13278">ps</a>, <a href="https://arxiv.org/format/2512.13278">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AutoTool: Dynamic Tool Selection and Integration for <span class="search-hit mathjax">Agentic</span> Reasoning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zou%2C+J">Jiaru Zou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+L">Ling Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qi%2C+Y">Yunzhe Qi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+S">Sirui Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+M">Mengting Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+K">Ke Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+J">Jingrui He</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+M">Mengdi Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13278v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Agentic</span> reinforcement learning has advanced large language models (LLMs) to reason through long chain-of-thought trajectories while interleaving external tool use. Existing approaches assume a fixed inventory of tools, limiting LLM&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13278v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13278v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13278v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Agentic</span> reinforcement learning has advanced large language models (LLMs) to reason through long chain-of-thought trajectories while interleaving external tool use. Existing approaches assume a fixed inventory of tools, limiting LLM <span class="search-hit mathjax">agents</span>&#39; adaptability to new or evolving toolsets. We present AutoTool, a framework that equips LLM <span class="search-hit mathjax">agents</span> with dynamic tool-selection capabilities throughout their reasoning trajectories. We first construct a 200k dataset with explicit tool-selection rationales across 1,000+ tools and 100+ tasks spanning mathematics, science, code generation, and multimodal reasoning. Building on this data foundation, AutoTool employs a dual-phase optimization pipeline: (i) supervised and RL-based trajectory stabilization for coherent reasoning, and (ii) KL-regularized Plackett-Luce ranking to refine consistent multi-step tool selection. Across ten diverse benchmarks, we train two base models, Qwen3-8B and Qwen2.5-VL-7B, with AutoTool. With fewer parameters, AutoTool consistently outperforms advanced LLM <span class="search-hit mathjax">agents</span> and tool-integration methods, yielding average gains of 6.4% in math &amp; science reasoning, 4.5% in search-based QA, 7.7% in code generation, and 6.9% in multimodal understanding. In addition, AutoTool exhibits stronger generalization by dynamically leveraging unseen tools from evolving toolsets during inference.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13278v1-abstract-full').style.display = 'none'; document.getElementById('2512.13278v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Best Paper Award at ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic Intelligence</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13268">arXiv:2512.13268</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13268">pdf</a>, <a href="https://arxiv.org/ps/2512.13268">ps</a>, <a href="https://arxiv.org/format/2512.13268">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SPARS: A Reinforcement Learning-Enabled Simulator for Power Management in HPC Job Scheduling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Amrizal%2C+M+A">Muhammad Alfian Amrizal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prasasta%2C+R+S">Raka Satya Prasasta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pradata%2C+S+Y">Santana Yuda Pradata</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Santiyuda%2C+K+G">Kadek Gemilang Santiyuda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pulungan%2C+R">Reza Pulungan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Takizawa%2C+H">Hiroyuki Takizawa</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13268v1-abstract-short" style="display: inline;">
        &hellip;framework. It supports traditional scheduling policies such as First Come First Served and EASY Backfilling, along with enhanced variants that employ reinforcement learning <span class="search-hit mathjax">agents</span> to dynamically decide when nodes should be powered on or off. Users can configure workloads and platforms in JSON format, specifying job arrivals, execution times, node power model&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13268v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13268v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13268v1-abstract-full" style="display: none;">
        High-performance computing (HPC) clusters consume enormous amounts of energy, with idle nodes as a major source of waste. Powering down unused nodes can mitigate this problem, but poorly timed transitions introduce long delays and reduce overall performance. To address this trade-off, we present SPARS, a reinforcement learning-enabled simulator for power management in HPC job scheduling. SPARS integrates job scheduling and node power state management within a discrete-event simulation framework. It supports traditional scheduling policies such as First Come First Served and EASY Backfilling, along with enhanced variants that employ reinforcement learning <span class="search-hit mathjax">agents</span> to dynamically decide when nodes should be powered on or off. Users can configure workloads and platforms in JSON format, specifying job arrivals, execution times, node power models, and transition delays. The simulator records comprehensive metrics-including energy usage, wasted power, job waiting times, and node utilization-and provides Gantt chart visualizations to analyze scheduling dynamics and power transitions. Unlike widely used Batsim-based frameworks that rely on heavy inter-process communication, SPARS provides lightweight event handling and consistent simulation results, making experiments easier to reproduce and extend. Its modular design allows new scheduling heuristics or learning algorithms to be integrated with minimal effort. By providing a flexible, reproducible, and extensible platform, SPARS enables researchers and practitioners to systematically evaluate power-aware scheduling strategies, explore the trade-offs between energy efficiency and performance, and accelerate the development of sustainable HPC operations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13268v1-abstract-full').style.display = 'none'; document.getElementById('2512.13268v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 4 figures, 5 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13262">arXiv:2512.13262</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13262">pdf</a>, <a href="https://arxiv.org/ps/2512.13262">ps</a>, <a href="https://arxiv.org/format/2512.13262">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Post-Training and Test-Time Scaling of Generative <span class="search-hit mathjax">Agent</span> Behavior Models for Interactive Autonomous Driving
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Seong%2C+H">Hyunki Seong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+J">Jeong-Kyun Lee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Myeong%2C+H">Heesoo Myeong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shin%2C+Y">Yongho Shin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cho%2C+H">Hyun-Mook Cho</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+D+H">Duck Hoon Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Desai%2C+P">Pranav Desai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Surana%2C+M">Monu Surana</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13262v1-abstract-short" style="display: inline;">
        Learning interactive motion behaviors among multiple <span class="search-hit mathjax">agents</span> is a core challenge in autonomous driving. While imitation learning models generate realistic trajectories, they often inherit biases from datasets dominated by safe demonstrations, limiting robustness in safety-critical cases. Moreover, most studies rely on open-loop evaluation, overlooking compoun&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13262v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13262v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13262v1-abstract-full" style="display: none;">
        Learning interactive motion behaviors among multiple <span class="search-hit mathjax">agents</span> is a core challenge in autonomous driving. While imitation learning models generate realistic trajectories, they often inherit biases from datasets dominated by safe demonstrations, limiting robustness in safety-critical cases. Moreover, most studies rely on open-loop evaluation, overlooking compounding errors in closed-loop execution. We address these limitations with two complementary strategies. First, we propose Group Relative Behavior Optimization (GRBO), a reinforcement learning post-training method that fine-tunes pretrained behavior models via group relative advantage maximization with human regularization. Using only 10% of the training dataset, GRBO improves safety performance by over 40% while preserving behavioral realism. Second, we introduce Warm-K, a warm-started Top-K sampling strategy that balances consistency and diversity in motion selection. Our Warm-K method-based test-time scaling enhances behavioral consistency and reactivity at test time without retraining, mitigating covariate shift and reducing performance discrepancies. Demo videos are available in the supplementary material.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13262v1-abstract-full').style.display = 'none'; document.getElementById('2512.13262v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11 pages, 5 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13253">arXiv:2512.13253</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13253">pdf</a>, <a href="https://arxiv.org/ps/2512.13253">ps</a>, <a href="https://arxiv.org/format/2512.13253">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fostering human learning is crucial for boosting human-AI synergy
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+J">Julian Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Burton%2C+J+W">Jason W. Burton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hertwig%2C+R">Ralph Hertwig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kosch%2C+T">Thomas Kosch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kurvers%2C+R+H+J+M">Ralf H. J. M. Kurvers</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kurzenberger%2C+B">Benito Kurzenberger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lazik%2C+C">Christopher Lazik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Onnasch%2C+L">Linda Onnasch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rieger%2C+T">Tobias Rieger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Thoma%2C+A+I">Anna I. Thoma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wulff%2C+D+U">Dirk U. Wulff</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Herzog%2C+S+M">Stefan M. Herzog</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13253v1-abstract-short" style="display: inline;">
        &hellip;conditions that facilitate such human-AI synergy remains limited. A recent meta-analysis showed that, on average, human-AI combinations do not outperform the better individual <span class="search-hit mathjax">agent</span>, indicating overall negative human-AI synergy. We argue that this pessimistic conclusion arises from insufficient attention to human learning in the experimental designs used. To&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13253v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13253v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13253v1-abstract-full" style="display: none;">
        The collaboration between humans and artificial intelligence (AI) holds the promise of achieving superior outcomes compared to either acting alone. Nevertheless, our understanding of the conditions that facilitate such human-AI synergy remains limited. A recent meta-analysis showed that, on average, human-AI combinations do not outperform the better individual <span class="search-hit mathjax">agent</span>, indicating overall negative human-AI synergy. We argue that this pessimistic conclusion arises from insufficient attention to human learning in the experimental designs used. To substantiate this claim, we re-analyzed all 74 studies included in the original meta-analysis, which yielded two new findings. First, most previous research overlooked design features that foster human learning, such as providing trial-by-trial outcome feedback to participants. Second, our re-analysis, using robust Bayesian meta-regressions, demonstrated that studies providing outcome feedback show relatively higher synergy than those without outcome feedback. Crucially, when feedback is paired with AI explanations we tend to find positive human-AI synergy, while AI explanations provided without feedback were strongly linked to negative synergy, indicating that explanations are useful for synergy only when humans can learn to verify the AI&#39;s reliability through feedback. We conclude that the current literature underestimates the potential for human-AI collaboration because it predominantly relies on experimental designs that do not facilitate human learning, thus hindering humans from effectively adapting their collaboration strategies. We therefore advocate for a paradigm shift in human-AI interaction research that explicitly incorporates and tests human learning mechanisms to enhance our understanding of and support for successful human-AI collaboration.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13253v1-abstract-full').style.display = 'none'; document.getElementById('2512.13253v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13250">arXiv:2512.13250</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13250">pdf</a>, <a href="https://arxiv.org/ps/2512.13250">ps</a>, <a href="https://arxiv.org/format/2512.13250">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Toward Ambulatory Vision: Learning Visually-Grounded Active View Selection
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Koo%2C+J">Juil Koo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Choi%2C+D">Daehyeon Choi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Youn%2C+S">Sangwoo Youn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+P+Y">Phillip Y. Lee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sung%2C+M">Minhyuk Sung</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13250v1-abstract-short" style="display: inline;">
        Vision Language Models (VLMs) excel at visual question answering (VQA) but remain limited to snapshot vision, reasoning from static images. In contrast, embodied <span class="search-hit mathjax">agents</span> require ambulatory vision, actively moving to obtain more informative views. We introduce Visually Grounded Active View Selection (VG-AVS), a task that selects the most informative next viewp&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13250v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13250v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13250v1-abstract-full" style="display: none;">
        Vision Language Models (VLMs) excel at visual question answering (VQA) but remain limited to snapshot vision, reasoning from static images. In contrast, embodied <span class="search-hit mathjax">agents</span> require ambulatory vision, actively moving to obtain more informative views. We introduce Visually Grounded Active View Selection (VG-AVS), a task that selects the most informative next viewpoint using only the visual information in the current image, without relying on scene memory or external knowledge. To support this task, we construct a synthetic dataset with automatically generated paired query-target views and question-answer prompts. We also propose a framework that fine-tunes pretrained VLMs through supervised fine-tuning (SFT) followed by RL-based policy optimization. Our approach achieves strong question answering performance based on viewpoint selection and generalizes robustly to unseen synthetic and real scenes. Furthermore, incorporating our learned VG-AVS framework into existing scene-exploration-based EQA systems improves downstream question-answering accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13250v1-abstract-full').style.display = 'none'; document.getElementById('2512.13250v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Project page: https://active-view-selection.github.io/</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13244">arXiv:2512.13244</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13244">pdf</a>, <a href="https://arxiv.org/ps/2512.13244">ps</a>, <a href="https://arxiv.org/format/2512.13244">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Theoretical Economics">econ.TH</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fair Coordination in Strategic Scheduling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+W">Wei-Chen Lee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bullinger%2C+M">Martin Bullinger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abate%2C+A">Alessandro Abate</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wooldridge%2C+M">Michael Wooldridge</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13244v1-abstract-short" style="display: inline;">
        We consider a scheduling problem of strategic <span class="search-hit mathjax">agents</span> representing jobs of different weights. Each&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13244v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13244v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13244v1-abstract-full" style="display: none;">
        We consider a scheduling problem of strategic <span class="search-hit mathjax">agents</span> representing jobs of different weights. Each <span class="search-hit mathjax">agent</span> has to decide on one of a finite set of identical machines to get their job processed. In contrast to the common and exclusive focus on makespan minimization, we want the outcome to be fair under strategic considerations of the <span class="search-hit mathjax">agents</span>. Two natural properties are credibility, which ensures that the assignment is a Nash equilibrium and equality, requiring that <span class="search-hit mathjax">agents</span> with equal-weight jobs are assigned to machines of equal load. We combine these two with a hierarchy of fairness properties based on envy-freeness together with several relaxations based on the idea that envy seems more justified towards <span class="search-hit mathjax">agents</span> with a higher weight. We present a complete complexity landscape for satisfiability and decision versions of these properties, alone or in combination, and study them as structural constraints under makespan optimization. For our positive results, we develop a unified algorithmic approach, where we achieve different properties by fine-tuning key subroutines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13244v1-abstract-full').style.display = 'none'; document.getElementById('2512.13244v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13191">arXiv:2512.13191</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13191">pdf</a>, <a href="https://arxiv.org/ps/2512.13191">ps</a>, <a href="https://arxiv.org/format/2512.13191">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CoRA: A Collaborative Robust Architecture with Hybrid Fusion for Efficient Perception
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+G">Gong Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chaokun Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lv%2C+P">Pengcheng Lv</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+X">Xiaohui Xie</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13191v1-abstract-short" style="display: inline;">
        Collaborative perception has garnered significant attention as a crucial technology to overcome the perceptual limitations of single-<span class="search-hit mathjax">agent</span> systems. Many state-of-the-art (SOTA) methods have achieved communication efficiency and high performance via intermediate fusion. However, they share a critical vulnerability: their performance degrades under adverse com&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13191v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13191v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13191v1-abstract-full" style="display: none;">
        Collaborative perception has garnered significant attention as a crucial technology to overcome the perceptual limitations of single-<span class="search-hit mathjax">agent</span> systems. Many state-of-the-art (SOTA) methods have achieved communication efficiency and high performance via intermediate fusion. However, they share a critical vulnerability: their performance degrades under adverse communication conditions due to the misalignment induced by data transmission, which severely hampers their practical deployment. To bridge this gap, we re-examine different fusion paradigms, and recover that the strengths of intermediate and late fusion are not a trade-off, but a complementary pairing. Based on this key insight, we propose CoRA, a novel collaborative robust architecture with a hybrid approach to decouple performance from robustness with low communication. It is composed of two components: a feature-level fusion branch and an object-level correction branch. Its first branch selects critical features and fuses them efficiently to ensure both performance and scalability. The second branch leverages semantic relevance to correct spatial displacements, guaranteeing resilience against pose errors. Experiments demonstrate the superiority of CoRA. Under extreme scenarios, CoRA improves upon its baseline performance by approximately 19% in AP@0.7 with more than 5x less communication volume, which makes it a promising solution for robust collaborative perception.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13191v1-abstract-full').style.display = 'none'; document.getElementById('2512.13191v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by AAAI2026</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13168">arXiv:2512.13168</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13168">pdf</a>, <a href="https://arxiv.org/ps/2512.13168">ps</a>, <a href="https://arxiv.org/format/2512.13168">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Finch: Benchmarking Finance &amp; Accounting across Spreadsheet-Centric Enterprise Workflows
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+H">Haoyu Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+P">Pengkun Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+Y">Yan Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+X">Xuanyu Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+Y">Yilin Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+M">Mingzhe Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yakefu%2C+A">Adina Yakefu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+S">Shuxin Zheng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13168v1-abstract-short" style="display: inline;">
        We introduce a finance &amp; accounting benchmark (Finch) for evaluating AI <span class="search-hit mathjax">agents</span> on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13168v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13168v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13168v1-abstract-full" style="display: none;">
        We introduce a finance &amp; accounting benchmark (Finch) for evaluating AI <span class="search-hit mathjax">agents</span> on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.
  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.
  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI <span class="search-hit mathjax">agents</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13168v1-abstract-full').style.display = 'none'; document.getElementById('2512.13168v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13159">arXiv:2512.13159</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13159">pdf</a>, <a href="https://arxiv.org/ps/2512.13159">ps</a>, <a href="https://arxiv.org/format/2512.13159">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Acikgoz%2C+E+C">Emre Can Acikgoz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Oh%2C+J">Jinoh Oh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hao%2C+J">Jie Hao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jeon%2C+J+H">Joo Hyuk Jeon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ji%2C+H">Heng Ji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hakkani-T%C3%BCr%2C+D">Dilek Hakkani-Tür</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tur%2C+G">Gokhan Tur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+C">Chengyuan Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+X">Xing Fan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13159v1-abstract-short" style="display: inline;">
        Effective human-<span class="search-hit mathjax">agent</span> collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13159v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13159v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13159v1-abstract-full" style="display: none;">
        Effective human-<span class="search-hit mathjax">agent</span> collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to <span class="search-hit mathjax">agents</span>, where <span class="search-hit mathjax">agents</span> respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these <span class="search-hit mathjax">agents</span> require more proactive engagement, where <span class="search-hit mathjax">agents</span> should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing <span class="search-hit mathjax">agents</span> as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances <span class="search-hit mathjax">agents</span>&#39; conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching <span class="search-hit mathjax">agents</span> to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-<span class="search-hit mathjax">agent</span> interactions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13159v1-abstract-full').style.display = 'none'; document.getElementById('2512.13159v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13154">arXiv:2512.13154</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13154">pdf</a>, <a href="https://arxiv.org/ps/2512.13154">ps</a>, <a href="https://arxiv.org/format/2512.13154">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        MAC: A Multi-<span class="search-hit mathjax">Agent</span> Framework for Interactive User Clarification in Multi-turn Conversations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Acikgoz%2C+E+C">Emre Can Acikgoz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Oh%2C+J">Jinoh Oh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jeon%2C+J+H">Joo Hyuk Jeon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hao%2C+J">Jie Hao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ji%2C+H">Heng Ji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hakkani-T%C3%BCr%2C+D">Dilek Hakkani-Tür</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tur%2C+G">Gokhan Tur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+C">Chengyuan Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+X">Xing Fan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13154v1-abstract-short" style="display: inline;">
        Conversational <span class="search-hit mathjax">agents</span> often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13154v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13154v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13154v1-abstract-full" style="display: none;">
        Conversational <span class="search-hit mathjax">agents</span> often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-<span class="search-hit mathjax">agent</span> architectures to manage complex conversational scenarios efficiently, ambiguity resolution remains a critical and underexplored challenge--particularly due to the difficulty of determining which <span class="search-hit mathjax">agent</span> should initiate a clarification and how <span class="search-hit mathjax">agents</span> should coordinate their actions when faced with uncertain or incomplete user input. The fundamental questions of when to interrupt a user and how to formulate the optimal clarification query within the most optimal multi-<span class="search-hit mathjax">agent</span> settings remain open. In this paper, we propose MAC (Multi-<span class="search-hit mathjax">Agent</span> Clarification), an interactive multi-<span class="search-hit mathjax">agent</span> framework specifically optimized to resolve user ambiguities by strategically managing clarification dialogues. We first introduce a novel taxonomy categorizing user ambiguities to systematically guide clarification strategies. Then, we present MAC that autonomously coordinates multiple <span class="search-hit mathjax">agents</span> to interact synergistically with users. Empirical evaluations on MultiWOZ 2.4 demonstrate that enabling clarification at both levels increases task success rate 7.8\% (54.5 to 62.3) and reduces the average number of dialogue turns (6.53 to 4.86) by eliciting all required user information up front and minimizing repetition. Our findings highlight the importance of active user interaction and role-aware clarification for more reliable human-<span class="search-hit mathjax">agent</span> communication.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13154v1-abstract-full').style.display = 'none'; document.getElementById('2512.13154v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13102">arXiv:2512.13102</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13102">pdf</a>, <a href="https://arxiv.org/ps/2512.13102">ps</a>, <a href="https://arxiv.org/format/2512.13102">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Socratic Students: Teaching Language Models to Learn by Asking Questions
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ambati%2C+R+B">Rajeev Bhatt Ambati</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Niu%2C+T">Tianyi Niu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Singh%2C+A">Aashu Singh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mishra%2C+S">Shlok Mishra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Srivastava%2C+S">Shashank Srivastava</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chaturvedi%2C+S">Snigdha Chaturvedi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13102v1-abstract-short" style="display: inline;">
        &hellip;such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive <span class="search-hit mathjax">agent</span> would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the s&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13102v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13102v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13102v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive <span class="search-hit mathjax">agent</span> would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provides guidance. In this work, we shift the focus to the student and investigate effective strategies to actively query the teacher in seeking useful information. Across math and coding benchmarks, where baseline student models begin with near-zero performance, we show that student-led approaches consistently yield absolute Pass@k improvements of at least 0.5 over static baselines. To improve question quality, we train students using Direct Preference Optimization (DPO) with guidance from either self or stronger students. We find that this guided training enables smaller models to learn how to ask better questions, further enhancing learning efficiency.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13102v1-abstract-full').style.display = 'none'; document.getElementById('2512.13102v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13096">arXiv:2512.13096</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13096">pdf</a>, <a href="https://arxiv.org/ps/2512.13096">ps</a>, <a href="https://arxiv.org/format/2512.13096">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Toward Self-Healing Networks-on-Chip: RL-Driven Routing in 2D Torus Architectures
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Charrwi%2C+M+W">Mohammad Walid Charrwi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hussain%2C+Z">Zaid Hussain</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13096v1-abstract-short" style="display: inline;">
        &hellip;learning RL based strategy to an adaptive routing baseline A torus topology is used for its low diameter high connectivity properties The RL approach models each router as an <span class="search-hit mathjax">agent</span> that learns to forward packets based on network state while the adaptive scheme uses fixed minimal paths with simple rerouting around faults We implement both methods in simulatio&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13096v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13096v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13096v1-abstract-full" style="display: none;">
        We investigate adaptive minimal routing in 2D torus networks on chip NoCs under node fault conditions comparing a reinforcement learning RL based strategy to an adaptive routing baseline A torus topology is used for its low diameter high connectivity properties The RL approach models each router as an <span class="search-hit mathjax">agent</span> that learns to forward packets based on network state while the adaptive scheme uses fixed minimal paths with simple rerouting around faults We implement both methods in simulation injecting up to 50 node faults uniformly at random Key metrics are measured 1 throughput vs offered load at fault density 02 2 packet delivery ratio PDR vs fault density and 3 a fault adaptive score FT vs fault density Experimental results show the RL method achieves significantly higher throughput at high load approximately 2030 gain and maintains higher reliability under increasing faults The RL router delivers more packets per cycle and adapts to faults by exploiting path diversity whereas the adaptive scheme degrades sharply as faults accumulate In particular the RL approach preserves end to end connectivity longer PDR remains above 90 until approximately 3040 faults while adaptive PDR drops to approximately 70 at the same point The fault adaptive score likewise favors RL routing Thus RL based adaptive routing demonstrates clear advantages in throughput and fault resilience for torus NoCs
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13096v1-abstract-full').style.display = 'none'; document.getElementById('2512.13096v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13060">arXiv:2512.13060</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13060">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+K">Kangning Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+Y">Yi Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nie%2C+C">Cong Nie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+W">Wei Li</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13060v1-abstract-short" style="display: inline;">
        &hellip;based on deep Q-learning. The framework formalizes the ETL scheduling process as a Markov Decision Process and enables adaptive decision-making by a reinforcement learning <span class="search-hit mathjax">agent</span> in high-dimensional state spaces to dynamically optimize task allocation and resource scheduling. The model consists of a state representation module, a feature embedding network, a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13060v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13060v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13060v1-abstract-full" style="display: none;">
        This paper addresses the challenges of low scheduling efficiency, unbalanced resource allocation, and poor adaptability in ETL (Extract-Transform-Load) processes under heterogeneous data environments by proposing an intelligent scheduling optimization framework based on deep Q-learning. The framework formalizes the ETL scheduling process as a Markov Decision Process and enables adaptive decision-making by a reinforcement learning <span class="search-hit mathjax">agent</span> in high-dimensional state spaces to dynamically optimize task allocation and resource scheduling. The model consists of a state representation module, a feature embedding network, a Q-value estimator, and a reward evaluation mechanism, which collectively consider task dependencies, node load states, and data flow characteristics to derive the optimal scheduling strategy in complex environments. A multi-objective reward function is designed to balance key performance indicators such as average scheduling delay, task completion rate, throughput, and resource utilization. Sensitivity experiments further verify the model&#39;s robustness under changes in hyperparameters, environmental dynamics, and data scale. Experimental results show that the proposed deep Q-learning scheduling framework significantly reduces scheduling delay, improves system throughput, and enhances execution stability under multi-source heterogeneous task conditions, demonstrating the strong potential of reinforcement learning in complex data scheduling and resource management, and providing an efficient and scalable optimization strategy for intelligent data pipeline construction.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13060v1-abstract-full').style.display = 'none'; document.getElementById('2512.13060v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13059">arXiv:2512.13059</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13059">pdf</a>, <a href="https://arxiv.org/ps/2512.13059">ps</a>, <a href="https://arxiv.org/format/2512.13059">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Open and Reproducible Deep Research <span class="search-hit mathjax">Agent</span> for Long-Form Question Answering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yamada%2C+I">Ikuya Yamada</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ikeda%2C+W">Wataru Ikeda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yoshida%2C+K">Ko Yoshida</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ye%2C+M">Mengyu Ye</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sugimoto%2C+H">Hinata Sugimoto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Suzuki%2C+M">Masatoshi Suzuki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ozaki%2C+H">Hisanori Ozaki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Suzuki%2C+J">Jun Suzuki</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13059v1-abstract-short" style="display: inline;">
        We present an open deep research system for long-form question answering, selected as a winning system in the text-to-text track of the MMU-RAG competition at NeurIPS 2025. The system combines an open-source large language model (LLM) with an open web search API to perform iterative retrieval, reasoning, and synthesis in real-world open-domain settings. To enhance reasoning quality, we apply prefe&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13059v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13059v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13059v1-abstract-full" style="display: none;">
        We present an open deep research system for long-form question answering, selected as a winning system in the text-to-text track of the MMU-RAG competition at NeurIPS 2025. The system combines an open-source large language model (LLM) with an open web search API to perform iterative retrieval, reasoning, and synthesis in real-world open-domain settings. To enhance reasoning quality, we apply preference tuning based on LLM-as-a-judge feedback that evaluates multiple aspects, including clarity, insightfulness, and factuality. Our experimental results show that the proposed method consistently improves answer quality across all three aspects. Our source code is publicly available at https://github.com/efficient-deep-research/efficient-deep-research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13059v1-abstract-full').style.display = 'none'; document.getElementById('2512.13059v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Technical report of a winning system in the NeurIPS MMU-RAG competition</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13047">arXiv:2512.13047</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13047">pdf</a>, <a href="https://arxiv.org/ps/2512.13047">ps</a>, <a href="https://arxiv.org/format/2512.13047">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Operating Systems">cs.OS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sharpen the Spec, Cut the Code: A Case for Generative File System with SYSSPEC
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Q">Qingyuan Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mo%2C+Z">Zou Mo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Hengbin Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+D">Dong Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xia%2C+Y">Yubin Xia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+H">Haibo Chen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13047v1-abstract-short" style="display: inline;">
        &hellip;that operates on the specification itself, enabling new features to be added without violating existing invariants. Moreover, the SYSSPEC toolchain features a set of LLM-based <span class="search-hit mathjax">agents</span> with mechanisms to mitigate hallucination during construction and evolution. We demonstrate our approach by generating SPECFS, a concurrent file system. SPECFS passes hundreds o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13047v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13047v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13047v1-abstract-full" style="display: none;">
        File systems are critical OS components that require constant evolution to support new hardware and emerging application needs. However, the traditional paradigm of developing features, fixing bugs, and maintaining the system incurs significant overhead, especially as systems grow in complexity. This paper proposes a new paradigm, generative file systems, which leverages Large Language Models (LLMs) to generate and evolve a file system from prompts, effectively addressing the need for robust evolution. Despite the widespread success of LLMs in code generation, attempts to create a functional file system have thus far been unsuccessful, mainly due to the ambiguity of natural language prompts.
  This paper introduces SYSSPEC, a framework for developing generative file systems. Its key insight is to replace ambiguous natural language with principles adapted from formal methods. Instead of imprecise prompts, SYSSPEC employs a multi-part specification that accurately describes a file system&#39;s functionality, modularity, and concurrency. The specification acts as an unambiguous blueprint, guiding LLMs to generate expected code flexibly. To manage evolution, we develop a DAG-structured patch that operates on the specification itself, enabling new features to be added without violating existing invariants. Moreover, the SYSSPEC toolchain features a set of LLM-based <span class="search-hit mathjax">agents</span> with mechanisms to mitigate hallucination during construction and evolution. We demonstrate our approach by generating SPECFS, a concurrent file system. SPECFS passes hundreds of regression tests, matching a manually-coded baseline. We further confirm its evolvability by seamlessly integrating 10 real-world features from Ext4. Our work shows that a specification-guided approach makes generating and evolving complex systems not only feasible but also highly effective.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13047v1-abstract-full').style.display = 'none'; document.getElementById('2512.13047v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13043">arXiv:2512.13043</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13043">pdf</a>, <a href="https://arxiv.org/ps/2512.13043">ps</a>, <a href="https://arxiv.org/format/2512.13043">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for <span class="search-hit mathjax">Agentic</span> VLM Training
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wei%2C+T">Tong Wei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Y">Yijun Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Changhao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xing%2C+J">Junliang Xing</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+Y">Yuanchun Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+Z">Zongqing Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ye%2C+D">Deheng Ye</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13043v1-abstract-short" style="display: inline;">
        Multi-turn reinforcement learning (RL) for multi-modal <span class="search-hit mathjax">agents</span> built upon vision-language models (VLMs) is hampered by sparse rewards and long-horizon credit assignment. Recent methods densify the reward by querying a teacher that provides step-level feedback, e.g., Guided Thought Reinforcement (GTR) and On-Policy Distillation, but rely on costly, often privi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13043v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13043v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13043v1-abstract-full" style="display: none;">
        Multi-turn reinforcement learning (RL) for multi-modal <span class="search-hit mathjax">agents</span> built upon vision-language models (VLMs) is hampered by sparse rewards and long-horizon credit assignment. Recent methods densify the reward by querying a teacher that provides step-level feedback, e.g., Guided Thought Reinforcement (GTR) and On-Policy Distillation, but rely on costly, often privileged models as the teacher, limiting practicality and reproducibility. We introduce GTR-Turbo, a highly efficient upgrade to GTR, which matches the performance without training or querying an expensive teacher model. Specifically, GTR-Turbo merges the weights of checkpoints produced during the ongoing RL training, and then uses this merged model as a &#34;free&#34; teacher to guide the subsequent RL via supervised fine-tuning or soft logit distillation. This design removes dependence on privileged VLMs (e.g., GPT or Gemini), mitigates the &#34;entropy collapse&#34; observed in prior work, and keeps training stable. Across diverse visual <span class="search-hit mathjax">agentic</span> tasks, GTR-Turbo improves the accuracy of the baseline model by 10-30% while reducing wall-clock training time by 50% and compute cost by 60% relative to GTR.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13043v1-abstract-full').style.display = 'none'; document.getElementById('2512.13043v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13030">arXiv:2512.13030</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13030">pdf</a>, <a href="https://arxiv.org/ps/2512.13030">ps</a>, <a href="https://arxiv.org/format/2512.13030">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Motus: A Unified Latent Action World Model
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bi%2C+H">Hongzhe Bi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tan%2C+H">Hengkai Tan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+S">Shenghao Xie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zeyuan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+S">Shuhe Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+H">Haitian Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+R">Ruowen Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+Y">Yao Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiang%2C+C">Chendong Xiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rong%2C+Y">Yinze Rong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+H">Hongyan Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+H">Hanyu Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Su%2C+Z">Zhizhong Su</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+L">Lei Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Su%2C+H">Hang Su</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+J">Jun Zhu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13030v1-abstract-short" style="display: inline;">
        While a general embodied <span class="search-hit mathjax">agent</span> must function as a unified system, current methods are built on isolated models for understanding, world modeling, and control. This fragmentation prevents unifying multimodal generative capabilities and hinders learning from large-scale, heterogeneous data. In this paper, we propose Motus, a unified latent action world model t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13030v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13030v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13030v1-abstract-full" style="display: none;">
        While a general embodied <span class="search-hit mathjax">agent</span> must function as a unified system, current methods are built on isolated models for understanding, world modeling, and control. This fragmentation prevents unifying multimodal generative capabilities and hinders learning from large-scale, heterogeneous data. In this paper, we propose Motus, a unified latent action world model that leverages existing general pretrained models and rich, sharable motion information. Motus introduces a Mixture-of-Transformer (MoT) architecture to integrate three experts (i.e., understanding, video generation, and action) and adopts a UniDiffuser-style scheduler to enable flexible switching between different modeling modes (i.e., world models, vision-language-action models, inverse dynamics models, video generation models, and video-action joint prediction models). Motus further leverages the optical flow to learn latent actions and adopts a recipe with three-phase training pipeline and six-layer data pyramid, thereby extracting pixel-level &#34;delta action&#34; and enabling large-scale action pretraining. Experiments show that Motus achieves superior performance against state-of-the-art methods in both simulation (a +15% improvement over X-VLA and a +45% improvement over Pi0.5) and real-world scenarios(improved by +11~48%), demonstrating unified modeling of all functionalities and priors significantly benefits downstream robotic tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13030v1-abstract-full').style.display = 'none'; document.getElementById('2512.13030v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.13021">arXiv:2512.13021</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.13021">pdf</a>, <a href="https://arxiv.org/ps/2512.13021">ps</a>, <a href="https://arxiv.org/format/2512.13021">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Safe Control of Multi-<span class="search-hit mathjax">Agent</span> Systems with Minimal Communication
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+M">Mo Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+J">Jing Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ozay%2C+N">Necmiye Ozay</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.13021v1-abstract-short" style="display: inline;">
        In many multi-<span class="search-hit mathjax">agent</span> systems, communication is limited by bandwidth, latency, and energy constraints. Designing controllers that achieve coordination and safety with minimal communication is critical for scalable and reliable deployment. This paper presents a method for designing controllers that minimize inter-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13021v1-abstract-full').style.display = 'inline'; document.getElementById('2512.13021v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.13021v1-abstract-full" style="display: none;">
        In many multi-<span class="search-hit mathjax">agent</span> systems, communication is limited by bandwidth, latency, and energy constraints. Designing controllers that achieve coordination and safety with minimal communication is critical for scalable and reliable deployment. This paper presents a method for designing controllers that minimize inter-<span class="search-hit mathjax">agent</span> communication in multi-<span class="search-hit mathjax">agent</span> systems while satisfying safety and coordination requirements, while conforming to communication delay constraints. The control synthesis problem is cast as a rank minimization problem, where a convex relaxation is obtained via system level synthesis. Simulation results on various tasks, including trajectory tracking with relative and heterogeneous sensing, demonstrate that the proposed method significantly reduces inter-<span class="search-hit mathjax">agent</span> transmission compared to baseline approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.13021v1-abstract-full').style.display = 'none'; document.getElementById('2512.13021v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">to appear at 2025 IEEE Conference on Decision and Control (CDC)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12989">arXiv:2512.12989</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12989">pdf</a>, <a href="https://arxiv.org/ps/2512.12989">ps</a>, <a href="https://arxiv.org/format/2512.12989">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Quantigence: A Multi-<span class="search-hit mathjax">Agent</span> AI Framework for Quantum Security Research
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Alquwayfili%2C+A">Abdulmalik Alquwayfili</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12989v1-abstract-short" style="display: inline;">
        &hellip;is hindered by the velocity of research, evolving NIST standards, and heterogeneous deployment environments. To address this, we present Quantigence, a theory-driven multi-<span class="search-hit mathjax">agent</span> AI framework for structured quantum-security analysis. Quantigence decomposes research objectives into specialized roles - Cryptographic Analyst, Threat Modeler, Standards Specialist&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12989v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12989v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12989v1-abstract-full" style="display: none;">
        Cryptographically Relevant Quantum Computers (CRQCs) pose a structural threat to the global digital economy. Algorithms like Shor&#39;s factoring and Grover&#39;s search threaten to dismantle the public-key infrastructure (PKI) securing sovereign communications and financial transactions. While the timeline for fault-tolerant CRQCs remains probabilistic, the &#34;Store-Now, Decrypt-Later&#34; (SNDL) model necessitates immediate migration to Post-Quantum Cryptography (PQC). This transition is hindered by the velocity of research, evolving NIST standards, and heterogeneous deployment environments. To address this, we present Quantigence, a theory-driven multi-<span class="search-hit mathjax">agent</span> AI framework for structured quantum-security analysis. Quantigence decomposes research objectives into specialized roles - Cryptographic Analyst, Threat Modeler, Standards Specialist, and Risk Assessor - coordinated by a supervisory <span class="search-hit mathjax">agent</span>. Using &#34;cognitive parallelism,&#34; <span class="search-hit mathjax">agents</span> reason independently to maintain context purity while execution is serialized on resource-constrained hardware (e.g., NVIDIA RTX 2060). The framework integrates external knowledge via the Model Context Protocol (MCP) and prioritizes vulnerabilities using the Quantum-Adjusted Risk Score (QARS), a formal extension of Mosca&#39;s Theorem. Empirical validation shows Quantigence achieves a 67% reduction in research turnaround time and superior literature coverage compared to manual workflows, democratizing access to high-fidelity quantum risk assessment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12989v1-abstract-full').style.display = 'none'; document.getElementById('2512.12989v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages, 2 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          94A60; 68T42
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          K.6.5; I.2.11; E.3
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12967">arXiv:2512.12967</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12967">pdf</a>, <a href="https://arxiv.org/ps/2512.12967">ps</a>, <a href="https://arxiv.org/format/2512.12967">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+W">Weizhou Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Z">Ziyi Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+C">Chenliang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+Z">Zhiyuan Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+M">Miao Peng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+H">Huashan Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+Y">Yingcheng Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liao%2C+S">Shengyi Liao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lai%2C+S">Shaopeng Lai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+B">Bo Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+D">Dayiheng Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+F">Fei Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+J">Jingren Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+M">Ming Yan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12967v1-abstract-short" style="display: inline;">
        &hellip;GPT-5 and Gemini-2.5-Pro on long-context reasoning benchmarks, surpassing its baseline by 9.90 points on average. On ultra-long tasks (1M~4M tokens), QwenLong-L1.5&#39;s memory-<span class="search-hit mathjax">agent</span> framework yields a 9.48-point gain over the <span class="search-hit mathjax">agent</span> baseline. Additionally, the acquired long-context reasoning ability translates to enhan&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12967v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12967v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12967v1-abstract-full" style="display: none;">
        We introduce QwenLong-L1.5, a model that achieves superior long-context reasoning capabilities through systematic post-training innovations. The key technical breakthroughs of QwenLong-L1.5 are as follows: (1) Long-Context Data Synthesis Pipeline: We develop a systematic synthesis framework that generates challenging reasoning tasks requiring multi-hop grounding over globally distributed evidence. By deconstructing documents into atomic facts and their underlying relationships, and then programmatically composing verifiable reasoning questions, our approach creates high-quality training data at scale, moving substantially beyond simple retrieval tasks to enable genuine long-range reasoning capabilities. (2) Stabilized Reinforcement Learning for Long-Context Training: To overcome the critical instability in long-context RL, we introduce task-balanced sampling with task-specific advantage estimation to mitigate reward bias, and propose Adaptive Entropy-Controlled Policy Optimization (AEPO) that dynamically regulates exploration-exploitation trade-offs. (3) Memory-Augmented Architecture for Ultra-Long Contexts: Recognizing that even extended context windows cannot accommodate arbitrarily long sequences, we develop a memory management framework with multi-stage fusion RL training that seamlessly integrates single-pass reasoning with iterative memory-based processing for tasks exceeding 4M tokens. Based on Qwen3-30B-A3B-Thinking, QwenLong-L1.5 achieves performance comparable to GPT-5 and Gemini-2.5-Pro on long-context reasoning benchmarks, surpassing its baseline by 9.90 points on average. On ultra-long tasks (1M~4M tokens), QwenLong-L1.5&#39;s memory-<span class="search-hit mathjax">agent</span> framework yields a 9.48-point gain over the <span class="search-hit mathjax">agent</span> baseline. Additionally, the acquired long-context reasoning ability translates to enhanced performance in general domains like scientific reasoning, memory tool using, and extended dialogue.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12967v1-abstract-full').style.display = 'none'; document.getElementById('2512.12967v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12950">arXiv:2512.12950</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12950">pdf</a>, <a href="https://arxiv.org/ps/2512.12950">ps</a>, <a href="https://arxiv.org/format/2512.12950">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s10506-025-09490-6">10.1007/s10506-025-09490-6 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Building from Scratch: A Multi-<span class="search-hit mathjax">Agent</span> Framework with Human-in-the-Loop for Multilingual Legal Terminology Mapping
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Meng%2C+L">Lingyi Meng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+M">Maolin Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+Y">Yilan Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Q">Qi Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mohanmmed%2C+I">Idlkaid Mohanmmed</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12950v1-abstract-short" style="display: inline;">
        &hellip;tools for these languages are limited. To address this, we propose a human-AI collaborative approach for building a multilingual legal terminology database, based on a multi-<span class="search-hit mathjax">agent</span> framework. This approach integrates advanced large language models and legal domain experts throughout the entire process-from raw document preprocessing, article-level alignment,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12950v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12950v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12950v1-abstract-full" style="display: none;">
        Accurately mapping legal terminology across languages remains a significant challenge, especially for language pairs like Chinese and Japanese, which share a large number of homographs with different meanings. Existing resources and standardized tools for these languages are limited. To address this, we propose a human-AI collaborative approach for building a multilingual legal terminology database, based on a multi-<span class="search-hit mathjax">agent</span> framework. This approach integrates advanced large language models and legal domain experts throughout the entire process-from raw document preprocessing, article-level alignment, to terminology extraction, mapping, and quality assurance. Unlike a single automated pipeline, our approach places greater emphasis on how human experts participate in this multi-<span class="search-hit mathjax">agent</span> system. Humans and AI <span class="search-hit mathjax">agents</span> take on different roles: AI <span class="search-hit mathjax">agents</span> handle specific, repetitive tasks, such as OCR, text segmentation, semantic alignment, and initial terminology extraction, while human experts provide crucial oversight, review, and supervise the outputs with contextual knowledge and legal judgment. We tested the effectiveness of this framework using a trilingual parallel corpus comprising 35 key Chinese statutes, along with their English and Japanese translations. The experimental results show that this human-in-the-loop, multi-<span class="search-hit mathjax">agent</span> workflow not only improves the precision and consistency of multilingual legal terminology mapping but also offers greater scalability compared to traditional manual methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12950v1-abstract-full').style.display = 'none'; document.getElementById('2512.12950v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">43 pages, 6 fingures, accepted in Artificial Intelligence and Law (2025)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12935">arXiv:2512.12935</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12935">pdf</a>, <a href="https://arxiv.org/ps/2512.12935">ps</a>, <a href="https://arxiv.org/format/2512.12935">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Thanh%2C+T+L+N">Toan Le Ngo Thanh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huu%2C+P+H">Phat Ha Huu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duy%2C+T+N+D">Tan Nguyen Dang Duy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Minh%2C+T+N+L">Thong Nguyen Le Minh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tinh%2C+A+N+N">Anh Nguyen Nhu Tinh</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12935v1-abstract-short" style="display: inline;">
        &hellip;scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, <span class="search-hit mathjax">Agent</span>-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion el&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12935v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12935v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12935v1-abstract-full" style="display: none;">
        The exponential growth of video content has created an urgent need for efficient multimodal moment retrieval systems. However, existing approaches face three critical challenges: (1) fixed-weight fusion strategies fail across cross modal noise and ambiguous queries, (2) temporal modeling struggles to capture coherent event sequences while penalizing unrealistic gaps, and (3) systems require manual modality selection, reducing usability. We propose a unified multimodal moment retrieval system with three key innovations. First, a cascaded dual-embedding pipeline combines BEIT-3 and SigLIP for broad retrieval, refined by BLIP-2 based reranking to balance recall and precision. Second, a temporal-aware scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, <span class="search-hit mathjax">Agent</span>-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion eliminating manual modality selection. Qualitative analysis demonstrates that our system effectively handles ambiguous queries, retrieves temporally coherent sequences, and dynamically adapts fusion strategies, advancing interactive moment search capabilities.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12935v1-abstract-full').style.display = 'none'; document.getElementById('2512.12935v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at AAAI Workshop 2026</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12921">arXiv:2512.12921</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12921">pdf</a>, <a href="https://arxiv.org/ps/2512.12921">ps</a>, <a href="https://arxiv.org/format/2512.12921">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Cisco Integrated AI Security and Safety Framework Report
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chang%2C+A">Amy Chang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Saade%2C+T">Tiffany Saade</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mendapara%2C+S">Sanket Mendapara</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Swanda%2C+A">Adam Swanda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+A">Ankit Garg</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12921v1-abstract-short" style="display: inline;">
        &hellip;(AI) systems are being readily and rapidly adopted, increasingly permeating critical domains: from consumer platforms and enterprise software to networked systems with embedded <span class="search-hit mathjax">agents</span>. While this has unlocked potential for human productivity gains, the attack surface has expanded accordingly: threats now span content safety failures (e.g., harmful or decepti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12921v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12921v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12921v1-abstract-full" style="display: none;">
        Artificial intelligence (AI) systems are being readily and rapidly adopted, increasingly permeating critical domains: from consumer platforms and enterprise software to networked systems with embedded <span class="search-hit mathjax">agents</span>. While this has unlocked potential for human productivity gains, the attack surface has expanded accordingly: threats now span content safety failures (e.g., harmful or deceptive outputs), model and data integrity compromise (e.g., poisoning, supply-chain tampering), runtime manipulations (e.g., prompt injection, tool and <span class="search-hit mathjax">agent</span> misuse), and ecosystem risks (e.g., orchestration abuse, multi-<span class="search-hit mathjax">agent</span> collusion). Existing frameworks such as MITRE ATLAS, National Institute of Standards and Technology (NIST) AI 100-2 Adversarial Machine Learning (AML) taxonomy, and OWASP Top 10s for Large Language Models (LLMs) and <span class="search-hit mathjax">Agentic</span> AI Applications provide valuable viewpoints, but each covers only slices of this multi-dimensional space.
  This paper presents Cisco&#39;s Integrated AI Security and Safety Framework (&#34;AI Security Framework&#34;), a unified, lifecycle-aware taxonomy and operationalization framework that can be used to classify, integrate, and operationalize the full range of AI risks. It integrates AI security and AI safety across modalities, <span class="search-hit mathjax">agents</span>, pipelines, and the broader ecosystem. The AI Security Framework is designed to be practical for threat identification, red-teaming, risk prioritization, and it is comprehensive in scope and can be extensible to emerging deployments in multimodal contexts, humanoids, wearables, and sensory infrastructures. We analyze gaps in prevailing frameworks, discuss design principles for our framework, and demonstrate how the taxonomy provides structure for understanding how modern AI systems fail, how adversaries exploit these failures, and how organizations can build defenses across the AI lifecycle that evolve alongside capability advancements.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12921v1-abstract-full').style.display = 'none'; document.getElementById('2512.12921v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12856">arXiv:2512.12856</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12856">pdf</a>, <a href="https://arxiv.org/ps/2512.12856">ps</a>, <a href="https://arxiv.org/format/2512.12856">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Forgetful but Faithful: A Cognitive Memory Architecture and Benchmark for Privacy-Aware Generative <span class="search-hit mathjax">Agents</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Alqithami%2C+S">Saad Alqithami</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12856v1-abstract-short" style="display: inline;">
        As generative <span class="search-hit mathjax">agents</span> become increasingly sophisticated and deployed in long-term interactive scenarios, their memory management capabilities emerge as a critical bottleneck for both performance and privacy. Current approaches either maintain unlimited memory stores, leading to computational intractability and privacy concerns, or employ simplistic forgetting&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12856v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12856v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12856v1-abstract-full" style="display: none;">
        As generative <span class="search-hit mathjax">agents</span> become increasingly sophisticated and deployed in long-term interactive scenarios, their memory management capabilities emerge as a critical bottleneck for both performance and privacy. Current approaches either maintain unlimited memory stores, leading to computational intractability and privacy concerns, or employ simplistic forgetting mechanisms that compromise <span class="search-hit mathjax">agent</span> coherence and functionality. This paper introduces the Memory-Aware Retention Schema (MaRS), a novel framework for human-centered memory management in generative <span class="search-hit mathjax">agents</span>, coupled with six theoretically-grounded forgetting policies that balance performance, privacy, and computational efficiency. We present the Forgetful but Faithful <span class="search-hit mathjax">Agent</span> (FiFA) benchmark, a comprehensive evaluation framework that assesses <span class="search-hit mathjax">agent</span> performance across narrative coherence, goal completion, social recall accuracy, privacy preservation, and cost efficiency. Through extensive experimentation involving 300 evaluation runs across multiple memory budgets and <span class="search-hit mathjax">agent</span> configurations, we demonstrate that our hybrid forgetting policy achieves superior performance (composite score: 0.911) while maintaining computational tractability and privacy guarantees. Our work establishes new benchmarks for memory-budgeted <span class="search-hit mathjax">agent</span> evaluation and provides practical guidelines for deploying generative <span class="search-hit mathjax">agents</span> in resource-constrained, privacy-sensitive environments. The theoretical foundations, implementation framework, and empirical results contribute to the emerging field of human-centered AI by addressing fundamental challenges in <span class="search-hit mathjax">agent</span> memory management that directly impact user trust, system scalability, and regulatory compliance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12856v1-abstract-full').style.display = 'none'; document.getElementById('2512.12856v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12818">arXiv:2512.12818</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12818">pdf</a>, <a href="https://arxiv.org/ps/2512.12818">ps</a>, <a href="https://arxiv.org/format/2512.12818">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hindsight is 20/20: Building <span class="search-hit mathjax">Agent</span> Memory that Retains, Recalls, and Reflects
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Latimer%2C+C">Chris Latimer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boschi%2C+N">Nicoló Boschi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Neeser%2C+A">Andrew Neeser</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bartholomew%2C+C">Chris Bartholomew</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Srivastava%2C+G">Gaurav Srivastava</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+X">Xuan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ramakrishnan%2C+N">Naren Ramakrishnan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12818v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Agent</span> memory has been touted as a dimension of growth for LLM-based applications, enabling&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12818v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12818v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12818v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Agent</span> memory has been touted as a dimension of growth for LLM-based applications, enabling <span class="search-hit mathjax">agents</span> that can accumulate experience, adapt across sessions, and move beyond single-shot question answering. The current generation of <span class="search-hit mathjax">agent</span> memory systems treats memory as an external layer that extracts salient snippets from conversations, stores them in vector or graph-based stores, and retrieves top-k items into the prompt of an otherwise stateless model. While these systems improve personalization and context carry-over, they still blur the line between evidence and inference, struggle to organize information over long horizons, and offer limited support for <span class="search-hit mathjax">agents</span> that must explain their reasoning. We present Hindsight, a memory architecture that treats <span class="search-hit mathjax">agent</span> memory as a structured, first-class substrate for reasoning by organizing it into four logical networks that distinguish world facts, <span class="search-hit mathjax">agent</span> experiences, synthesized entity summaries, and evolving beliefs. This framework supports three core operations -- retain, recall, and reflect -- that govern how information is added, accessed, and updated. Under this abstraction, a temporal, entity aware memory layer incrementally turns conversational streams into a structured, queryable memory bank, while a reflection layer reasons over this bank to produce answers and to update information in a traceable way. On key long-horizon conversational memory benchmarks like LongMemEval and LoCoMo, Hindsight with an open-source 20B model lifts overall accuracy from 39% to 83.6% over a full-context baseline with the same backbone and outperforms full context GPT-4o. Scaling the backbone further pushes Hindsight to 91.4% on LongMemEval and up to 89.61% on LoCoMo (vs. 75.78% for the strongest prior open system), consistently outperforming existing memory architectures on multi-session and open-domain questions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12818v1-abstract-full').style.display = 'none'; document.getElementById('2512.12818v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12806">arXiv:2512.12806</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12806">pdf</a>, <a href="https://arxiv.org/ps/2512.12806">ps</a>, <a href="https://arxiv.org/format/2512.12806">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fault-Tolerant Sandboxing for AI Coding <span class="search-hit mathjax">Agents</span>: A Transactional Approach to Safe Autonomous Execution
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+B">Boyang Yan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12806v1-abstract-short" style="display: inline;">
        The transition of Large Language Models (LLMs) from passive code generators to autonomous <span class="search-hit mathjax">agents</span> introduces significant safety risks, specifically regarding destructive commands and inconsistent system states. Existing commercial solutions often prioritize interactive user safety, enforcing authentication barriers that break the headless loops required for t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12806v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12806v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12806v1-abstract-full" style="display: none;">
        The transition of Large Language Models (LLMs) from passive code generators to autonomous <span class="search-hit mathjax">agents</span> introduces significant safety risks, specifically regarding destructive commands and inconsistent system states. Existing commercial solutions often prioritize interactive user safety, enforcing authentication barriers that break the headless loops required for true autonomy. This paper presents a Fault-Tolerant Sandboxing framework designed to mitigate these risks through a policy-based interception layer and a transactional filesystem snapshot mechanism. We hypothesize that wrapping <span class="search-hit mathjax">agent</span> actions in atomic transactions can guarantee safety with acceptable latency, outperforming the heavy initialization overhead of containers or the interactive friction of commercial CLIs. We validated this approach by deploying the Minimind-MoE LLM served via nano-vllm on a custom Proxmox-based testbed utilizing EVPN/VXLAN isolation. Experimental results demonstrate a 100\% interception rate for high-risk commands and a 100\% success rate in rolling back failed states. Crucially, our prototype incurs only a 14.5\% performance overhead (approx. 1.8s) per transaction. In contrast, benchmarking against the Gemini CLI sandbox revealed that it requires interactive authentication (&#34;Sign in&#34;), rendering it unusable for headless, autonomous <span class="search-hit mathjax">agent</span> workflows.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12806v1-abstract-full').style.display = 'none'; document.getElementById('2512.12806v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12803">arXiv:2512.12803</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12803">pdf</a>, <a href="https://arxiv.org/ps/2512.12803">ps</a>, <a href="https://arxiv.org/format/2512.12803">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Distributed Reinforcement Learning using Local Smart Meter Data for Voltage Regulation in Distribution Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+D">Dong Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Giraldo%2C+J+S">Juan S. Giraldo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Palensky%2C+P">Peter Palensky</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vergara%2C+P+P">Pedro P. Vergara</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12803v1-abstract-short" style="display: inline;">
        Centralised reinforcement learning (RL) for voltage magnitude regulation in distribution networks typically involves numerous <span class="search-hit mathjax">agent</span>-environment interactions and power flow (PF) calculations, inducing computational overhead and privacy concerns over shared data. Thus, we propose a distributed RL algorithm to regulate voltage magnitude. First, a dynamic Theven&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12803v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12803v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12803v1-abstract-full" style="display: none;">
        Centralised reinforcement learning (RL) for voltage magnitude regulation in distribution networks typically involves numerous <span class="search-hit mathjax">agent</span>-environment interactions and power flow (PF) calculations, inducing computational overhead and privacy concerns over shared data. Thus, we propose a distributed RL algorithm to regulate voltage magnitude. First, a dynamic Thevenin equivalent model is integrated within smart meters (SM), enabling local voltage magnitude estimation using local SM data for RL <span class="search-hit mathjax">agent</span> training, and mitigating the dependency of synchronised data collection and centralised PF calculations. To mitigate estimation errors induced by Thevenin model inaccuracies, a voltage magnitude correction strategy that combines piecewise functions and neural networks is introduced. The piecewise function corrects the large errors of estimated voltage magnitude, while a neural network mimics the grid&#39;s sensitivity to control actions, improving action adjustment precision. Second, a coordination strategy is proposed to refine local RL <span class="search-hit mathjax">agent</span> actions online, preventing voltage magnitude violations induced by excessive actions from multiple independently trained <span class="search-hit mathjax">agents</span>. Case studies on energy storage systems validate the feasibility and effectiveness of the proposed approach, demonstrating its potential to improve voltage regulation in distribution networks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12803v1-abstract-full').style.display = 'none'; document.getElementById('2512.12803v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12791">arXiv:2512.12791</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12791">pdf</a>, <a href="https://arxiv.org/ps/2512.12791">ps</a>, <a href="https://arxiv.org/format/2512.12791">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Beyond Task Completion: An Assessment Framework for Evaluating <span class="search-hit mathjax">Agentic</span> AI Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Akshathala%2C+S">Sreemaee Akshathala</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adnan%2C+B">Bassam Adnan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ramesh%2C+M">Mahisha Ramesh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vaidhyanathan%2C+K">Karthik Vaidhyanathan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Muhammed%2C+B">Basil Muhammed</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Parthasarathy%2C+K">Kannan Parthasarathy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12791v1-abstract-short" style="display: inline;">
        Recent advances in <span class="search-hit mathjax">agentic</span> AI have shifted the focus from standalone Large Language Models (LLMs) to integrated systems that combine LLMs with tools, memory, and other&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12791v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12791v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12791v1-abstract-full" style="display: none;">
        Recent advances in <span class="search-hit mathjax">agentic</span> AI have shifted the focus from standalone Large Language Models (LLMs) to integrated systems that combine LLMs with tools, memory, and other <span class="search-hit mathjax">agents</span> to perform complex tasks. These multi-<span class="search-hit mathjax">agent</span> architectures enable coordinated reasoning, planning, and execution across diverse domains, allowing <span class="search-hit mathjax">agents</span> to collaboratively automate complex workflows. Despite these advances, evaluation and assessment of LLM <span class="search-hit mathjax">agents</span> and the multi-<span class="search-hit mathjax">agent</span> systems they constitute remain a fundamental challenge. Although various approaches have been proposed in the software engineering literature for evaluating conventional software components, existing methods for AI-based systems often overlook the non-deterministic nature of models. This non-determinism introduces behavioral uncertainty during execution, yet existing evaluations rely on binary task completion metrics that fail to capture it. Evaluating <span class="search-hit mathjax">agentic</span> systems therefore requires examining additional dimensions, including the <span class="search-hit mathjax">agent</span> ability to invoke tools, ingest and retrieve memory, collaborate with other <span class="search-hit mathjax">agents</span>, and interact effectively with its environment. We propose an end-to-end <span class="search-hit mathjax">Agent</span> Assessment Framework with four evaluation pillars encompassing LLMs, Memory, Tools, and Environment. We validate the framework on a representative Autonomous CloudOps use case, where experiments reveal behavioral deviations overlooked by conventional metrics, demonstrating its effectiveness in capturing runtime uncertainties.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12791v1-abstract-full').style.display = 'none'; document.getElementById('2512.12791v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12730">arXiv:2512.12730</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12730">pdf</a>, <a href="https://arxiv.org/ps/2512.12730">ps</a>, <a href="https://arxiv.org/format/2512.12730">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NL2Repo-Bench: Towards Long-Horizon Repository Generation Evaluation of Coding <span class="search-hit mathjax">Agents</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+J">Jingzhe Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Long%2C+S">Shengda Long</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pu%2C+C">Changxin Pu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+H">Huan Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+H">Hongwan Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+X">Xiang Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+C">Chao He</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hou%2C+Y">Yue Hou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+F">Fei Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zhaojian Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+W">Weiran Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zaiyuan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zan%2C+D">Daoguang Zan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chenchen Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+X">Xiaoxu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Q">Qizhi Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+X">Xianfu Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deng%2C+B">Bo Deng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gu%2C+Q">Qingshui Gu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hua%2C+K">Kai Hua</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+J">Juntao Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+P">Pai Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+M">Mingchen Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pan%2C+X">Xuanguang Pan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+Z">Zifan Peng</a>
      , et al. (23 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12730v1-abstract-short" style="display: inline;">
        Recent advances in coding <span class="search-hit mathjax">agents</span> suggest rapid progress toward autonomous software development, yet existing benchmarks fail to rigorously evaluate the long-horizon capabilities required to build complete software systems. Most prior evaluations focus on localized code generation, scaffolded completion, or short-term repair tasks, leaving open the question o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12730v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12730v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12730v1-abstract-full" style="display: none;">
        Recent advances in coding <span class="search-hit mathjax">agents</span> suggest rapid progress toward autonomous software development, yet existing benchmarks fail to rigorously evaluate the long-horizon capabilities required to build complete software systems. Most prior evaluations focus on localized code generation, scaffolded completion, or short-term repair tasks, leaving open the question of whether <span class="search-hit mathjax">agents</span> can sustain coherent reasoning, planning, and execution over the extended horizons demanded by real-world repository construction. To address this gap, we present NL2Repo Bench, a benchmark explicitly designed to evaluate the long-horizon repository generation ability of coding <span class="search-hit mathjax">agents</span>. Given only a single natural-language requirements document and an empty workspace, <span class="search-hit mathjax">agents</span> must autonomously design the architecture, manage dependencies, implement multi-module logic, and produce a fully installable Python library. Our experiments across state-of-the-art open- and closed-source models reveal that long-horizon repository generation remains largely unsolved: even the strongest <span class="search-hit mathjax">agents</span> achieve below 40% average test pass rates and rarely complete an entire repository correctly. Detailed analysis uncovers fundamental long-horizon failure modes, including premature termination, loss of global coherence, fragile cross-file dependencies, and inadequate planning over hundreds of interaction steps. NL2Repo Bench establishes a rigorous, verifiable testbed for measuring sustained <span class="search-hit mathjax">agentic</span> competence and highlights long-horizon reasoning as a central bottleneck for the next generation of autonomous coding <span class="search-hit mathjax">agents</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12730v1-abstract-full').style.display = 'none'; document.getElementById('2512.12730v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12719">arXiv:2512.12719</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12719">pdf</a>, <a href="https://arxiv.org/ps/2512.12719">ps</a>, <a href="https://arxiv.org/format/2512.12719">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards AI <span class="search-hit mathjax">Agents</span> Supported Research Problem Formulation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pereira%2C+A+F">Anrafel Fernandes Pereira</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baldassarre%2C+M+T">Maria Teresa Baldassarre</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mendez%2C+D">Daniel Mendez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kalinowski%2C+M">Marcos Kalinowski</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12719v1-abstract-short" style="display: inline;">
        &hellip;the practical relevance of Software Engineering studies by not reflecting the complexities of industrial practice. This vision paper explores the use of artificial intelligence <span class="search-hit mathjax">agents</span> to support SE researchers during the early stage of a research project, the formulation of the research problem. Based on the Lean Research Inception framework and using a publ&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12719v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12719v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12719v1-abstract-full" style="display: none;">
        Poorly formulated research problems can compromise the practical relevance of Software Engineering studies by not reflecting the complexities of industrial practice. This vision paper explores the use of artificial intelligence <span class="search-hit mathjax">agents</span> to support SE researchers during the early stage of a research project, the formulation of the research problem. Based on the Lean Research Inception framework and using a published study on code maintainability in machine learning as a reference, we developed a descriptive evaluation of a scenario illustrating how AI <span class="search-hit mathjax">agents</span>, integrated into LRI, can support SE researchers by pre filling problem attributes, aligning stakeholder perspectives, refining research questions, simulating multiperspective assessments, and supporting decision making. The descriptive evaluation of the scenario suggests that AI <span class="search-hit mathjax">agent</span> support can enrich collaborative discussions and enhance critical reflection on the value, feasibility, and applicability of the research problem. Although the vision of integrating AI <span class="search-hit mathjax">agents</span> into LRI was perceived as promising to support the context aware and practice oriented formulation of research problems, empirical validation is needed to confirm and refine the integration of AI <span class="search-hit mathjax">agents</span> into problem formulation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12719v1-abstract-full').style.display = 'none'; document.getElementById('2512.12719v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12717">arXiv:2512.12717</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12717">pdf</a>, <a href="https://arxiv.org/ps/2512.12717">ps</a>, <a href="https://arxiv.org/format/2512.12717">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        HMPCC: Human-Aware Model Predictive Coverage Control
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Catellani%2C+M">Mattia Catellani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gabbi%2C+M">Marta Gabbi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sabattini%2C+L">Lorenzo Sabattini</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12717v1-abstract-short" style="display: inline;">
        We address the problem of coordinating a team of robots to cover an unknown environment while ensuring safe operation and avoiding collisions with non-cooperative <span class="search-hit mathjax">agents</span>. Traditional coverage strategies often rely on simplified assumptions, such as known or convex environments and static density functions, and struggle to adapt to real-world scenarios, espec&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12717v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12717v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12717v1-abstract-full" style="display: none;">
        We address the problem of coordinating a team of robots to cover an unknown environment while ensuring safe operation and avoiding collisions with non-cooperative <span class="search-hit mathjax">agents</span>. Traditional coverage strategies often rely on simplified assumptions, such as known or convex environments and static density functions, and struggle to adapt to real-world scenarios, especially when humans are involved. In this work, we propose a human-aware coverage framework based on Model Predictive Control (MPC), namely HMPCC, where human motion predictions are integrated into the planning process. By anticipating human trajectories within the MPC horizon, robots can proactively coordinate their actions %avoid redundant exploration, and adapt to dynamic conditions. The environment is modeled as a Gaussian Mixture Model (GMM), representing regions of interest. Team members operate in a fully decentralized manner, without relying on explicit communication, an essential feature in hostile or communication-limited scenarios. Our results show that human trajectory forecasting enables more efficient and adaptive coverage, improving coordination between human and robotic <span class="search-hit mathjax">agents</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12717v1-abstract-full').style.display = 'none'; document.getElementById('2512.12717v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12716">arXiv:2512.12716</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12716">pdf</a>, <a href="https://arxiv.org/ps/2512.12716">ps</a>, <a href="https://arxiv.org/format/2512.12716">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3773966.3777986">10.1145/3773966.3777986 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CoDA: A Context-Decoupled Hierarchical <span class="search-hit mathjax">Agent</span> with Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+X">Xuanzhang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+J">Jianglun Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhuang%2C+Z">Zhuoran Zhuang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+J">Junzhe Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Que%2C+M">Maofei Que</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+J">Jieting Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+D">Dianlei Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tong%2C+H">Hao Tong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Ye Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+P">Pan Li</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12716v1-abstract-short" style="display: inline;">
        Large Language Model (LLM) <span class="search-hit mathjax">agents</span> trained with reinforcement learning (RL) show great promise for solving complex, multi-step tasks. However, their performance is often crippled by &#34;Context Explosion&#34;, where the accumulation of long text outputs overwhelms the model&#39;s context window and leads to reasoning failures. To address this, we introduce C&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12716v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12716v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12716v1-abstract-full" style="display: none;">
        Large Language Model (LLM) <span class="search-hit mathjax">agents</span> trained with reinforcement learning (RL) show great promise for solving complex, multi-step tasks. However, their performance is often crippled by &#34;Context Explosion&#34;, where the accumulation of long text outputs overwhelms the model&#39;s context window and leads to reasoning failures. To address this, we introduce CoDA, a Context-Decoupled hierarchical <span class="search-hit mathjax">Agent</span>, a simple but effective reinforcement learning framework that decouples high-level planning from low-level execution. It employs a single, shared LLM backbone that learns to operate in two distinct, contextually isolated roles: a high-level Planner that decomposes tasks within a concise strategic context, and a low-level Executor that handles tool interactions in an ephemeral, isolated workspace. We train this unified <span class="search-hit mathjax">agent</span> end-to-end using PECO (Planner-Executor Co-Optimization), a reinforcement learning methodology that applies a trajectory-level reward to jointly optimize both roles, fostering seamless collaboration through context-dependent policy updates. Extensive experiments demonstrate that CoDA achieves significant performance improvements over state-of-the-art baselines on complex multi-hop question-answering benchmarks, and it exhibits strong robustness in long-context scenarios, maintaining stable performance while all other baselines suffer severe degradation, thus further validating the effectiveness of our hierarchical design in mitigating context overload.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12716v1-abstract-full').style.display = 'none'; document.getElementById('2512.12716v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to WSDM &#39;26 Oral</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12706">arXiv:2512.12706</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12706">pdf</a>, <a href="https://arxiv.org/ps/2512.12706">ps</a>, <a href="https://arxiv.org/format/2512.12706">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mu%2C+E">Enhong Mu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yoda%2C+M">Minami Yoda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yan Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+M">Mingyue Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Matsuno%2C+Y">Yutaka Matsuno</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+J">Jialong Li</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12706v1-abstract-short" style="display: inline;">
        &hellip;automated testing approaches typically create a dichotomy: code-centric methods focus on structural coverage without understanding gameplay context, while player-centric <span class="search-hit mathjax">agents</span> validate high-level intent but often fail to cover specific underlying code changes. To bridge this gap, we propose SMART (Structural Mapping for Augmented Reinforcement Testing), a n&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12706v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12706v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12706v1-abstract-full" style="display: none;">
        The widespread adoption of the &#34;Games as a Service&#34; model necessitates frequent content updates, placing immense pressure on quality assurance. In response, automated game testing has been viewed as a promising solution to cope with this demanding release cadence. However, existing automated testing approaches typically create a dichotomy: code-centric methods focus on structural coverage without understanding gameplay context, while player-centric <span class="search-hit mathjax">agents</span> validate high-level intent but often fail to cover specific underlying code changes. To bridge this gap, we propose SMART (Structural Mapping for Augmented Reinforcement Testing), a novel framework that synergizes structural verification and functional validation for game update testing. SMART leverages large language models (LLMs) to interpret abstract syntax tree (AST) differences and extract functional intent, constructing a context-aware hybrid reward mechanism. This mechanism guides reinforcement learning <span class="search-hit mathjax">agents</span> to sequentially fulfill gameplay goals while adaptively exploring modified code branches. We evaluate SMART on two environments, Overcooked and Minecraft. The results demonstrate that SMART significantly outperforms state-of-the-art baselines; it achieves over 94% branch coverage of modified code, nearly double that of traditional reinforcement learning methods, while maintaining a 98% task completion rate, effectively balancing structural comprehensiveness with functional correctness.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12706v1-abstract-full').style.display = 'none'; document.getElementById('2512.12706v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12692">arXiv:2512.12692</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12692">pdf</a>, <a href="https://arxiv.org/ps/2512.12692">ps</a>, <a href="https://arxiv.org/format/2512.12692">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        WebOperator: Action-Aware Tree Search for Autonomous <span class="search-hit mathjax">Agents</span> in Web Environment
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dihan%2C+M+L">Mahir Labib Dihan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hashem%2C+T">Tanzima Hashem</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ali%2C+M+E">Mohammed Eunus Ali</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Parvez%2C+M+R">Md Rizwan Parvez</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12692v1-abstract-short" style="display: inline;">
        LLM-based <span class="search-hit mathjax">agents</span> often operate in a greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observable-limited to browser-visible content (e.g., DOM and UI elements)-w&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12692v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12692v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12692v1-abstract-full" style="display: none;">
        LLM-based <span class="search-hit mathjax">agents</span> often operate in a greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observable-limited to browser-visible content (e.g., DOM and UI elements)-where a single misstep often requires complex and brittle navigation to undo. Without an explicit backtracking mechanism, <span class="search-hit mathjax">agents</span> struggle to correct errors or systematically explore alternative paths. Tree-search methods provide a principled framework for such structured exploration, but existing approaches lack mechanisms for safe backtracking, making them prone to unintended side effects. They also assume that all actions are reversible, ignoring the presence of irreversible actions-limitations that reduce their effectiveness in realistic web tasks. To address these challenges, we introduce WebOperator, a tree-search framework that enables reliable backtracking and strategic exploration. Our method incorporates a best-first search strategy that ranks actions by both reward estimates and safety considerations, along with a robust backtracking mechanism that verifies the feasibility of previously visited paths before replaying them, preventing unintended side effects. To further guide exploration, WebOperator generates action candidates from multiple, varied reasoning contexts to ensure diverse and robust exploration, and subsequently curates a high-quality action set by filtering out invalid actions pre-execution and merging semantically equivalent ones. Experimental results on WebArena and WebVoyager demonstrate the effectiveness of WebOperator. On WebArena, WebOperator achieves a state-of-the-art 54.6% success rate with gpt-4o, underscoring the critical advantage of integrating strategic foresight with safe execution.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12692v1-abstract-full').style.display = 'none'; document.getElementById('2512.12692v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Under review at ICLR 2026. Project page: https://kagnlp.github.io/WebOperator/</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12686">arXiv:2512.12686</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12686">pdf</a>, <a href="https://arxiv.org/ps/2512.12686">ps</a>, <a href="https://arxiv.org/format/2512.12686">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Memoria: A Scalable <span class="search-hit mathjax">Agentic</span> Memory Framework for Personalized Conversational AI
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sarin%2C+S">Samarth Sarin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Singh%2C+L">Lovepreet Singh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sarmah%2C+B">Bhaskarjit Sarmah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mehta%2C+D">Dhagash Mehta</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12686v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Agentic</span> memory is emerging as a key enabler for large language models (LLM) to maintain continuity, personalization, and long-term context in extended user interactions, critical capabilities for deploying LLMs as truly interactive and adaptive&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12686v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12686v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12686v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Agentic</span> memory is emerging as a key enabler for large language models (LLM) to maintain continuity, personalization, and long-term context in extended user interactions, critical capabilities for deploying LLMs as truly interactive and adaptive <span class="search-hit mathjax">agents</span>. <span class="search-hit mathjax">Agentic</span> memory refers to the memory that provides an LLM with <span class="search-hit mathjax">agent</span>-like persistence: the ability to retain and act upon information across conversations, similar to how a human would. We present Memoria, a modular memory framework that augments LLM-based conversational systems with persistent, interpretable, and context-rich memory. Memoria integrates two complementary components: dynamic session-level summarization and a weighted knowledge graph (KG)-based user modelling engine that incrementally captures user traits, preferences, and behavioral patterns as structured entities and relationships. This hybrid architecture enables both short-term dialogue coherence and long-term personalization while operating within the token constraints of modern LLMs. We demonstrate how Memoria enables scalable, personalized conversational artificial intelligence (AI) by bridging the gap between stateless LLM interfaces and <span class="search-hit mathjax">agentic</span> memory systems, offering a practical solution for industry applications requiring adaptive and evolving user experiences.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12686v1-abstract-full').style.display = 'none'; document.getElementById('2512.12686v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Paper accepted at 5th International Conference of AIML Systems 2025, Bangalore, India</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12656">arXiv:2512.12656</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12656">pdf</a>, <a href="https://arxiv.org/ps/2512.12656">ps</a>, <a href="https://arxiv.org/format/2512.12656">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Argumentative Reasoning with Language Models on Non-factorized Case Bases
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fungwacharakorn%2C+W">Wachara Fungwacharakorn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zin%2C+M+M">May Myo Zin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nguyen%2C+H">Ha-Thanh Nguyen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kong%2C+Y">Yuntao Kong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Satoh%2C+K">Ken Satoh</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12656v1-abstract-short" style="display: inline;">
        In this paper, we investigate how language models can perform case-based reasoning (CBR) on non-factorized case bases. We introduce a novel framework, argumentative <span class="search-hit mathjax">agentic</span> models for case-based reasoning (AAM-CBR), which extends abstract argumentation for case-based reasoning (AA-CBR). Unlike traditional approaches that require factorization of previous cas&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12656v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12656v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12656v1-abstract-full" style="display: none;">
        In this paper, we investigate how language models can perform case-based reasoning (CBR) on non-factorized case bases. We introduce a novel framework, argumentative <span class="search-hit mathjax">agentic</span> models for case-based reasoning (AAM-CBR), which extends abstract argumentation for case-based reasoning (AA-CBR). Unlike traditional approaches that require factorization of previous cases, AAM-CBR leverages language models to determine case coverage and extract factors based on new cases. This enables factor-based reasoning without exposing or preprocessing previous cases, thus improving both flexibility and privacy. We also present initial experiments to assess AAM-CBR performance by comparing the proposed framework with a baseline that uses a single-prompt approach to incorporate both new and previous cases. The experiments are conducted based on a synthetic credit card application dataset. The result shows that AAM-CBR surpasses the baseline only when the new case contains a richer set of factors. The finding indicates that language models can handle case-based reasoning with a limited number of factors, but face challenges as the number of factors increase. Consequently, integrating symbolic reasoning with language models, as implemented in AAM-CBR, is crucial for effectively handling cases involving many factors.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12656v1-abstract-full').style.display = 'none'; document.getElementById('2512.12656v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented at NeLaMKRR@KR, 2025 (arXiv:2511.09575)</span>
    </p>
    

    
      <p class="comments is-size-7">
        
          <span class="has-text-black-bis has-text-weight-semibold">Report number:</span>
          NeLaMKRR/2025/01
        

        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2512.12653">arXiv:2512.12653</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2512.12653">pdf</a>, <a href="https://arxiv.org/ps/2512.12653">ps</a>, <a href="https://arxiv.org/format/2512.12653">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Econometrics">econ.EM</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Theoretical Economics">econ.TH</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Methodology">stat.ME</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Continuous Treatment Effects with Spatial and Network Spillovers
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kikuchi%2C+T">Tatsuru Kikuchi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2512.12653v1-abstract-short" style="display: inline;">
        &hellip;effects that propagate through geographic space and economic networks. We derive a master equation governing propagation from three economic foundations -- heterogeneous <span class="search-hit mathjax">agent</span> aggregation, market equilibrium, and cost minimization -- establishing that the framework rests on fundamental principles rather than ad hoc specifications. A key result shows that the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12653v1-abstract-full').style.display = 'inline'; document.getElementById('2512.12653v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2512.12653v1-abstract-full" style="display: none;">
        This paper develops a continuous functional framework for treatment effects that propagate through geographic space and economic networks. We derive a master equation governing propagation from three economic foundations -- heterogeneous <span class="search-hit mathjax">agent</span> aggregation, market equilibrium, and cost minimization -- establishing that the framework rests on fundamental principles rather than ad hoc specifications. A key result shows that the spatial-network interaction coefficient equals the mutual information between geographic and market coordinates. The Feynman-Kac representation decomposes effects into inherited and accumulated components along stochastic paths representing economic linkages. The framework nests the no-spillover case as a testable restriction. Monte Carlo simulations demonstrate that conventional estimators -- two-way fixed effects, difference-in-differences, and generalized propensity score -- exhibit 25-38% bias and severe undercoverage when spillovers exist, while our estimator maintains correct inference regardless of whether spillovers are present. Applying the framework to U.S. minimum wage policy, we reject the no-spillover null and find total effects at state borders four times larger than direct effects -- conventional methods capture only one-quarter of policy impact. Structural estimates reveal spatial diffusion consistent with commuting-distance labor mobility, network diffusion consistent with quarterly supply chain adjustment, and significant spatial-network interaction reflecting geographic clustering of industries. Entropy-based fragility diagnostics outperform standard centrality measures by 56-76% in predicting labor market disruptions, identifying all high-risk state-industry pairs during 2020-2021 with six-month advance warning.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2512.12653v1-abstract-full').style.display = 'none'; document.getElementById('2512.12653v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">109 pages, 5 figures</span>
    </p>
    

    

    
  </li>

</ol>


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
                                     
          
          <li>
            <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=50"
              class="pagination-link "
              aria-label="Page 2"
              aria-current="page">2
            </a>
          </li>
          
          <li>
            <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=100"
              class="pagination-link "
              aria-label="Page 3"
              aria-current="page">3
            </a>
          </li>
          
          <li>
            <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=150"
              class="pagination-link "
              aria-label="Page 4"
              aria-current="page">4
            </a>
          </li>
          
          <li>
            <a href="/search/?query=agents&amp;searchtype=all&amp;source=header&amp;start=200"
              class="pagination-link "
              aria-label="Page 5"
              aria-current="page">5
            </a>
          </li>
          
          <li><span class="pagination-ellipsis">&hellip;</span></li>
        
      
    </ul>
  </nav>
  

  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>